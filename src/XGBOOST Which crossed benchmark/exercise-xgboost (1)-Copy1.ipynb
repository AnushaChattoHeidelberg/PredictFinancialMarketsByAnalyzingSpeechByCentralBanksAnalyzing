{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal XG Boost with the Bert Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-25T22:31:28.463998Z",
     "iopub.status.busy": "2022-12-25T22:31:28.463523Z",
     "iopub.status.idle": "2022-12-25T22:31:29.516594Z",
     "shell.execute_reply": "2022-12-25T22:31:29.515567Z",
     "shell.execute_reply.started": "2022-12-25T22:31:28.463955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renuk\\anaconda3\\envs\\harbar\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "#S-0) Importing the necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model without shuffling the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-25T22:37:03.890221Z",
     "iopub.status.busy": "2022-12-25T22:37:03.889544Z",
     "iopub.status.idle": "2022-12-25T22:37:04.375607Z",
     "shell.execute_reply": "2022-12-25T22:37:04.374610Z",
     "shell.execute_reply.started": "2022-12-25T22:37:03.890184Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_x = pd.read_csv('x_train_ACFqOMF.csv')\n",
    "bert_y = pd.read_csv('y_train_HNMbC27.csv',index_col = 0)\n",
    "bert_x_test  = pd.read_csv('x_test_pf4T2aK.csv')\n",
    "random_submission = pd.read_csv('random_submission_example.csv', index_col = 0)\n",
    "bert_x_train,bert_x_val,bert_y_train,bert_y_val = train_test_split(bert_x,bert_y,train_size = 0.8,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-25T22:37:05.490433Z",
     "iopub.status.busy": "2022-12-25T22:37:05.489616Z",
     "iopub.status.idle": "2022-12-25T22:37:05.498632Z",
     "shell.execute_reply": "2022-12-25T22:37:05.497632Z",
     "shell.execute_reply.started": "2022-12-25T22:37:05.490383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1619, 768)\n",
      "(1619, 39)\n",
      "(415, 768)\n"
     ]
    }
   ],
   "source": [
    "print(bert_x_train.shape) Inp\n",
    "print(bert_y_train.shape) Out\n",
    "print(bert_x_test.shape) Inp : 6/4\n",
    "415,39 : 6/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_758</th>\n",
       "      <th>embed_759</th>\n",
       "      <th>embed_760</th>\n",
       "      <th>embed_761</th>\n",
       "      <th>embed_762</th>\n",
       "      <th>embed_763</th>\n",
       "      <th>embed_764</th>\n",
       "      <th>embed_765</th>\n",
       "      <th>embed_766</th>\n",
       "      <th>embed_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.593896</td>\n",
       "      <td>-0.064762</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>-0.204985</td>\n",
       "      <td>-0.020191</td>\n",
       "      <td>-0.011442</td>\n",
       "      <td>-0.037963</td>\n",
       "      <td>-0.298239</td>\n",
       "      <td>-0.040236</td>\n",
       "      <td>0.546839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184453</td>\n",
       "      <td>-0.199293</td>\n",
       "      <td>0.051006</td>\n",
       "      <td>0.270629</td>\n",
       "      <td>-0.070993</td>\n",
       "      <td>-0.049700</td>\n",
       "      <td>0.183429</td>\n",
       "      <td>-0.659867</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.090459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.089499</td>\n",
       "      <td>-0.166100</td>\n",
       "      <td>0.122766</td>\n",
       "      <td>0.104867</td>\n",
       "      <td>0.008371</td>\n",
       "      <td>-0.074680</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>0.569398</td>\n",
       "      <td>-0.029840</td>\n",
       "      <td>-0.033208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246565</td>\n",
       "      <td>0.083387</td>\n",
       "      <td>-0.132592</td>\n",
       "      <td>-0.766148</td>\n",
       "      <td>-0.323153</td>\n",
       "      <td>-0.453999</td>\n",
       "      <td>0.173123</td>\n",
       "      <td>0.281454</td>\n",
       "      <td>-0.064343</td>\n",
       "      <td>-0.133666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013104</td>\n",
       "      <td>-0.290522</td>\n",
       "      <td>0.461759</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.055795</td>\n",
       "      <td>-0.102498</td>\n",
       "      <td>0.061132</td>\n",
       "      <td>0.434192</td>\n",
       "      <td>-0.164281</td>\n",
       "      <td>0.076892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.224350</td>\n",
       "      <td>-0.093638</td>\n",
       "      <td>-0.382246</td>\n",
       "      <td>-0.217971</td>\n",
       "      <td>-0.454239</td>\n",
       "      <td>0.082005</td>\n",
       "      <td>0.124396</td>\n",
       "      <td>-0.011094</td>\n",
       "      <td>-0.210619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.454174</td>\n",
       "      <td>0.121775</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>-0.048016</td>\n",
       "      <td>-0.105496</td>\n",
       "      <td>-0.216831</td>\n",
       "      <td>-0.173918</td>\n",
       "      <td>-0.101547</td>\n",
       "      <td>-0.209740</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359921</td>\n",
       "      <td>-0.006138</td>\n",
       "      <td>-0.038534</td>\n",
       "      <td>0.297223</td>\n",
       "      <td>0.057184</td>\n",
       "      <td>0.321524</td>\n",
       "      <td>-0.344735</td>\n",
       "      <td>-0.362957</td>\n",
       "      <td>-0.032909</td>\n",
       "      <td>0.134404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.471450</td>\n",
       "      <td>-0.109883</td>\n",
       "      <td>0.199362</td>\n",
       "      <td>-0.114269</td>\n",
       "      <td>-0.105862</td>\n",
       "      <td>-0.126005</td>\n",
       "      <td>0.099511</td>\n",
       "      <td>-0.063115</td>\n",
       "      <td>0.063890</td>\n",
       "      <td>0.042452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086798</td>\n",
       "      <td>-0.128025</td>\n",
       "      <td>0.083945</td>\n",
       "      <td>0.260165</td>\n",
       "      <td>-0.056105</td>\n",
       "      <td>0.339414</td>\n",
       "      <td>-0.006278</td>\n",
       "      <td>-0.446322</td>\n",
       "      <td>-0.017794</td>\n",
       "      <td>-0.002816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>-0.243373</td>\n",
       "      <td>-0.027258</td>\n",
       "      <td>0.096287</td>\n",
       "      <td>-0.185371</td>\n",
       "      <td>-0.393311</td>\n",
       "      <td>0.079776</td>\n",
       "      <td>-0.108790</td>\n",
       "      <td>0.265602</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.303618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.259550</td>\n",
       "      <td>0.059597</td>\n",
       "      <td>0.146899</td>\n",
       "      <td>0.177783</td>\n",
       "      <td>-0.071019</td>\n",
       "      <td>-0.267914</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>-0.273114</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>-0.224204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>-0.083569</td>\n",
       "      <td>-0.169147</td>\n",
       "      <td>0.109032</td>\n",
       "      <td>-0.360755</td>\n",
       "      <td>-0.048671</td>\n",
       "      <td>-0.126569</td>\n",
       "      <td>0.260053</td>\n",
       "      <td>0.108402</td>\n",
       "      <td>-0.012138</td>\n",
       "      <td>0.160421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062912</td>\n",
       "      <td>0.145780</td>\n",
       "      <td>0.140720</td>\n",
       "      <td>-0.254386</td>\n",
       "      <td>-0.075401</td>\n",
       "      <td>-0.213626</td>\n",
       "      <td>0.366412</td>\n",
       "      <td>-0.174309</td>\n",
       "      <td>0.144730</td>\n",
       "      <td>-0.328432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>-0.556751</td>\n",
       "      <td>-0.142130</td>\n",
       "      <td>0.168117</td>\n",
       "      <td>-0.168494</td>\n",
       "      <td>-0.017123</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.141587</td>\n",
       "      <td>-0.091136</td>\n",
       "      <td>0.137483</td>\n",
       "      <td>0.055062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263235</td>\n",
       "      <td>0.209520</td>\n",
       "      <td>-0.089775</td>\n",
       "      <td>0.343396</td>\n",
       "      <td>-0.152058</td>\n",
       "      <td>0.176508</td>\n",
       "      <td>0.145433</td>\n",
       "      <td>-0.357442</td>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.359638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>-0.652777</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>0.165587</td>\n",
       "      <td>-0.149536</td>\n",
       "      <td>-0.106974</td>\n",
       "      <td>0.239422</td>\n",
       "      <td>0.195469</td>\n",
       "      <td>-0.114583</td>\n",
       "      <td>0.098860</td>\n",
       "      <td>-0.055446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307012</td>\n",
       "      <td>0.238408</td>\n",
       "      <td>-0.133939</td>\n",
       "      <td>0.119817</td>\n",
       "      <td>0.174391</td>\n",
       "      <td>0.167489</td>\n",
       "      <td>0.242845</td>\n",
       "      <td>-0.387507</td>\n",
       "      <td>-0.150356</td>\n",
       "      <td>0.276186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>-0.477829</td>\n",
       "      <td>-0.186134</td>\n",
       "      <td>0.338807</td>\n",
       "      <td>-0.481670</td>\n",
       "      <td>0.056761</td>\n",
       "      <td>0.048165</td>\n",
       "      <td>0.272554</td>\n",
       "      <td>-0.109683</td>\n",
       "      <td>-0.040566</td>\n",
       "      <td>-0.142930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060973</td>\n",
       "      <td>0.211225</td>\n",
       "      <td>0.086952</td>\n",
       "      <td>0.013316</td>\n",
       "      <td>-0.167993</td>\n",
       "      <td>0.390378</td>\n",
       "      <td>-0.089116</td>\n",
       "      <td>-0.354401</td>\n",
       "      <td>-0.274617</td>\n",
       "      <td>0.252376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1619 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0    -0.593896 -0.064762  0.037443 -0.204985 -0.020191 -0.011442 -0.037963   \n",
       "1    -0.089499 -0.166100  0.122766  0.104867  0.008371 -0.074680  0.052226   \n",
       "2     0.013104 -0.290522  0.461759 -0.005823  0.055795 -0.102498  0.061132   \n",
       "3    -0.454174  0.121775  0.191489 -0.048016 -0.105496 -0.216831 -0.173918   \n",
       "4    -0.471450 -0.109883  0.199362 -0.114269 -0.105862 -0.126005  0.099511   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1614 -0.243373 -0.027258  0.096287 -0.185371 -0.393311  0.079776 -0.108790   \n",
       "1615 -0.083569 -0.169147  0.109032 -0.360755 -0.048671 -0.126569  0.260053   \n",
       "1616 -0.556751 -0.142130  0.168117 -0.168494 -0.017123  0.057328  0.141587   \n",
       "1617 -0.652777 -0.092177  0.165587 -0.149536 -0.106974  0.239422  0.195469   \n",
       "1618 -0.477829 -0.186134  0.338807 -0.481670  0.056761  0.048165  0.272554   \n",
       "\n",
       "       embed_7   embed_8   embed_9  ...  embed_758  embed_759  embed_760  \\\n",
       "0    -0.298239 -0.040236  0.546839  ...  -0.184453  -0.199293   0.051006   \n",
       "1     0.569398 -0.029840 -0.033208  ...  -0.246565   0.083387  -0.132592   \n",
       "2     0.434192 -0.164281  0.076892  ...   0.019520   0.224350  -0.093638   \n",
       "3    -0.101547 -0.209740  0.015478  ...  -0.359921  -0.006138  -0.038534   \n",
       "4    -0.063115  0.063890  0.042452  ...  -0.086798  -0.128025   0.083945   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1614  0.265602  0.103273  0.303618  ...  -0.259550   0.059597   0.146899   \n",
       "1615  0.108402 -0.012138  0.160421  ...  -0.062912   0.145780   0.140720   \n",
       "1616 -0.091136  0.137483  0.055062  ...   0.263235   0.209520  -0.089775   \n",
       "1617 -0.114583  0.098860 -0.055446  ...  -0.307012   0.238408  -0.133939   \n",
       "1618 -0.109683 -0.040566 -0.142930  ...  -0.060973   0.211225   0.086952   \n",
       "\n",
       "      embed_761  embed_762  embed_763  embed_764  embed_765  embed_766  \\\n",
       "0      0.270629  -0.070993  -0.049700   0.183429  -0.659867   0.085300   \n",
       "1     -0.766148  -0.323153  -0.453999   0.173123   0.281454  -0.064343   \n",
       "2     -0.382246  -0.217971  -0.454239   0.082005   0.124396  -0.011094   \n",
       "3      0.297223   0.057184   0.321524  -0.344735  -0.362957  -0.032909   \n",
       "4      0.260165  -0.056105   0.339414  -0.006278  -0.446322  -0.017794   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1614   0.177783  -0.071019  -0.267914   0.395459  -0.273114   0.009224   \n",
       "1615  -0.254386  -0.075401  -0.213626   0.366412  -0.174309   0.144730   \n",
       "1616   0.343396  -0.152058   0.176508   0.145433  -0.357442   0.091661   \n",
       "1617   0.119817   0.174391   0.167489   0.242845  -0.387507  -0.150356   \n",
       "1618   0.013316  -0.167993   0.390378  -0.089116  -0.354401  -0.274617   \n",
       "\n",
       "      embed_767  \n",
       "0      0.090459  \n",
       "1     -0.133666  \n",
       "2     -0.210619  \n",
       "3      0.134404  \n",
       "4     -0.002816  \n",
       "...         ...  \n",
       "1614  -0.224204  \n",
       "1615  -0.328432  \n",
       "1616   0.359638  \n",
       "1617   0.276186  \n",
       "1618   0.252376  \n",
       "\n",
       "[1619 rows x 768 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diff_VIX_1d</th>\n",
       "      <th>Diff_VIX_1w</th>\n",
       "      <th>Diff_VIX_2w</th>\n",
       "      <th>Diff_V2X_1d</th>\n",
       "      <th>Diff_V2X_1w</th>\n",
       "      <th>Diff_V2X_2w</th>\n",
       "      <th>Diff_EURUSD_1d</th>\n",
       "      <th>Diff_EURUSD_1w</th>\n",
       "      <th>Diff_EURUSD_2w</th>\n",
       "      <th>Diff_EURUSDV1M_1d</th>\n",
       "      <th>...</th>\n",
       "      <th>Diff_SPX_2w</th>\n",
       "      <th>Diff_SRVIX_1d</th>\n",
       "      <th>Diff_SRVIX_1w</th>\n",
       "      <th>Diff_SRVIX_2w</th>\n",
       "      <th>Diff_CVIX_1d</th>\n",
       "      <th>Diff_CVIX_1w</th>\n",
       "      <th>Diff_CVIX_2w</th>\n",
       "      <th>Diff_MOVE_1d</th>\n",
       "      <th>Diff_MOVE_1w</th>\n",
       "      <th>Diff_MOVE_2w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.4476</td>\n",
       "      <td>0.2496</td>\n",
       "      <td>1.1221</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.060258</td>\n",
       "      <td>-0.182817</td>\n",
       "      <td>0.09745</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>-0.5500</td>\n",
       "      <td>1.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.4391</td>\n",
       "      <td>-0.7112</td>\n",
       "      <td>6.1795</td>\n",
       "      <td>-0.0048</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.3675</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.86</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.92000</td>\n",
       "      <td>-0.1082</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>1.9018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.56</td>\n",
       "      <td>-0.3430</td>\n",
       "      <td>2.2993</td>\n",
       "      <td>2.3575</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>-0.0088</td>\n",
       "      <td>-0.3150</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.17</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.74</td>\n",
       "      <td>-0.140000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>-0.2249</td>\n",
       "      <td>-0.3166</td>\n",
       "      <td>2.8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>3.58</td>\n",
       "      <td>-0.2026</td>\n",
       "      <td>-2.4894</td>\n",
       "      <td>2.0213</td>\n",
       "      <td>-0.0099</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>-0.0409</td>\n",
       "      <td>-0.3350</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.383900</td>\n",
       "      <td>-0.175300</td>\n",
       "      <td>-0.75820</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>-11.0000</td>\n",
       "      <td>5.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>1.3956</td>\n",
       "      <td>3.3027</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>-0.0352</td>\n",
       "      <td>-0.0420</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>...</td>\n",
       "      <td>-40.07</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>2.20</td>\n",
       "      <td>6.30</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.37000</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>11.5193</td>\n",
       "      <td>25.4624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>-3.5801</td>\n",
       "      <td>-4.5860</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>-0.0066</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>...</td>\n",
       "      <td>13.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.330000</td>\n",
       "      <td>-0.920000</td>\n",
       "      <td>-0.56000</td>\n",
       "      <td>-0.2819</td>\n",
       "      <td>-4.7771</td>\n",
       "      <td>-0.4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>-1.26</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-8.01</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>-2.6543</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>-0.2425</td>\n",
       "      <td>...</td>\n",
       "      <td>37.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>-0.140000</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>-0.97000</td>\n",
       "      <td>-1.9156</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>-14.3860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>-0.63</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.3426</td>\n",
       "      <td>1.4305</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>-0.0141</td>\n",
       "      <td>-0.0211</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>1.39</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.4067</td>\n",
       "      <td>16.7837</td>\n",
       "      <td>6.2195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>1.8998</td>\n",
       "      <td>-1.5854</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>...</td>\n",
       "      <td>45.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>-0.59420</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>-0.7000</td>\n",
       "      <td>-11.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1.57</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>1.7410</td>\n",
       "      <td>-1.3512</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.033340</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>0.22176</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>-2.4000</td>\n",
       "      <td>-7.4277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1619 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Diff_VIX_1d  Diff_VIX_1w  Diff_VIX_2w  Diff_V2X_1d  Diff_V2X_1w  \\\n",
       "0            0.09         0.91         0.78      -0.4476       0.2496   \n",
       "1            0.40        -0.01         3.83       2.4391      -0.7112   \n",
       "2           -1.54         1.86         1.56      -0.3430       2.2993   \n",
       "3           -0.06        -0.99         3.58      -0.2026      -2.4894   \n",
       "4            0.14        -0.07         1.69       0.2685       1.3956   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1614        -0.07        -1.91        -0.33       0.3534      -3.5801   \n",
       "1615        -1.26        -0.31        -8.01       0.1307       0.0462   \n",
       "1616        -0.63         1.50         0.40      -0.3426       1.4305   \n",
       "1617         0.14         0.32        -4.64       0.1893       1.8998   \n",
       "1618         1.57         0.06         0.85       0.1800       1.7410   \n",
       "\n",
       "      Diff_V2X_2w  Diff_EURUSD_1d  Diff_EURUSD_1w  Diff_EURUSD_2w  \\\n",
       "0          1.1221          0.0067         -0.0038         -0.0053   \n",
       "1          6.1795         -0.0048          0.0034         -0.0046   \n",
       "2          2.3575         -0.0016          0.0039         -0.0088   \n",
       "3          2.0213         -0.0099         -0.0212         -0.0409   \n",
       "4          3.3027         -0.0059         -0.0352         -0.0420   \n",
       "...           ...             ...             ...             ...   \n",
       "1614      -4.5860         -0.0023         -0.0066          0.0011   \n",
       "1615      -2.6543          0.0020          0.0097          0.0085   \n",
       "1616       0.1979         -0.0093         -0.0141         -0.0211   \n",
       "1617      -1.5854         -0.0167         -0.0061          0.0304   \n",
       "1618      -1.3512          0.0017         -0.0018          0.0308   \n",
       "\n",
       "      Diff_EURUSDV1M_1d  ...  Diff_SPX_2w  Diff_SRVIX_1d  Diff_SRVIX_1w  \\\n",
       "0                0.0250  ...       -24.41           0.00           0.00   \n",
       "1               -0.3675  ...       -61.86          -0.16          -0.97   \n",
       "2               -0.3150  ...       -48.17           0.10           3.02   \n",
       "3               -0.3350  ...       -23.16           0.00           0.00   \n",
       "4                0.0150  ...       -40.07          -0.05           2.20   \n",
       "...                 ...  ...          ...            ...            ...   \n",
       "1614            -0.3400  ...        13.32           0.24          -0.38   \n",
       "1615            -0.2425  ...        37.50           0.01          -0.75   \n",
       "1616             0.2500  ...        -2.83           1.39           4.12   \n",
       "1617             0.4475  ...        45.30           0.00           0.00   \n",
       "1618            -0.1000  ...        32.01           0.00           0.00   \n",
       "\n",
       "      Diff_SRVIX_2w  Diff_CVIX_1d  Diff_CVIX_1w  Diff_CVIX_2w  Diff_MOVE_1d  \\\n",
       "0              0.00      0.060258     -0.182817       0.09745        0.4500   \n",
       "1             -0.17     -0.120000      0.090000       0.92000       -0.1082   \n",
       "2              3.74     -0.140000      0.170000       0.20000       -0.2249   \n",
       "3              0.00     -0.383900     -0.175300      -0.75820        1.1000   \n",
       "4              6.30     -0.170000      0.090000       1.37000        0.5353   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "1614           0.63     -0.330000     -0.920000      -0.56000       -0.2819   \n",
       "1615          -2.46     -0.140000     -0.310000      -0.97000       -1.9156   \n",
       "1616           3.48      0.280000      1.520000       0.90000        1.4067   \n",
       "1617           0.00      0.004400      0.471000      -0.59420        0.7000   \n",
       "1618           0.00     -0.033340      0.616300       0.22176        1.9000   \n",
       "\n",
       "      Diff_MOVE_1w  Diff_MOVE_2w  \n",
       "0          -0.5500        1.8500  \n",
       "1           0.9718        1.9018  \n",
       "2          -0.3166        2.8408  \n",
       "3         -11.0000        5.6000  \n",
       "4          11.5193       25.4624  \n",
       "...            ...           ...  \n",
       "1614       -4.7771       -0.4958  \n",
       "1615        0.0396      -14.3860  \n",
       "1616       16.7837        6.2195  \n",
       "1617       -0.7000      -11.3000  \n",
       "1618       -2.4000       -7.4277  \n",
       "\n",
       "[1619 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_758</th>\n",
       "      <th>embed_759</th>\n",
       "      <th>embed_760</th>\n",
       "      <th>embed_761</th>\n",
       "      <th>embed_762</th>\n",
       "      <th>embed_763</th>\n",
       "      <th>embed_764</th>\n",
       "      <th>embed_765</th>\n",
       "      <th>embed_766</th>\n",
       "      <th>embed_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>-0.504543</td>\n",
       "      <td>-0.238862</td>\n",
       "      <td>0.268207</td>\n",
       "      <td>-0.195398</td>\n",
       "      <td>-0.129295</td>\n",
       "      <td>-0.071738</td>\n",
       "      <td>-0.071930</td>\n",
       "      <td>-0.078853</td>\n",
       "      <td>0.193799</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078656</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.196333</td>\n",
       "      <td>-0.178815</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>-0.060292</td>\n",
       "      <td>-0.433548</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>0.099468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>-0.476096</td>\n",
       "      <td>-0.214239</td>\n",
       "      <td>-0.063099</td>\n",
       "      <td>-0.076593</td>\n",
       "      <td>-0.299466</td>\n",
       "      <td>-0.026293</td>\n",
       "      <td>-0.101854</td>\n",
       "      <td>0.181612</td>\n",
       "      <td>-0.097852</td>\n",
       "      <td>0.107278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084571</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>0.167772</td>\n",
       "      <td>0.129893</td>\n",
       "      <td>-0.125352</td>\n",
       "      <td>-0.338464</td>\n",
       "      <td>0.123560</td>\n",
       "      <td>-0.251659</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>-0.264190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>-0.110859</td>\n",
       "      <td>0.055071</td>\n",
       "      <td>-0.044472</td>\n",
       "      <td>-0.087786</td>\n",
       "      <td>-0.168676</td>\n",
       "      <td>0.216177</td>\n",
       "      <td>0.356343</td>\n",
       "      <td>0.203279</td>\n",
       "      <td>-0.012863</td>\n",
       "      <td>-0.026753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165248</td>\n",
       "      <td>0.271330</td>\n",
       "      <td>0.153580</td>\n",
       "      <td>-0.144125</td>\n",
       "      <td>-0.126144</td>\n",
       "      <td>-0.044800</td>\n",
       "      <td>0.281531</td>\n",
       "      <td>0.094203</td>\n",
       "      <td>0.042266</td>\n",
       "      <td>0.203444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>-0.505651</td>\n",
       "      <td>-0.113361</td>\n",
       "      <td>0.225261</td>\n",
       "      <td>-0.311196</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>-0.122159</td>\n",
       "      <td>0.551452</td>\n",
       "      <td>-0.142533</td>\n",
       "      <td>0.048752</td>\n",
       "      <td>0.323749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121238</td>\n",
       "      <td>0.069174</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>0.303918</td>\n",
       "      <td>-0.078248</td>\n",
       "      <td>0.339804</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>-0.463689</td>\n",
       "      <td>-0.051655</td>\n",
       "      <td>0.500953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>-0.285427</td>\n",
       "      <td>-0.194134</td>\n",
       "      <td>0.210919</td>\n",
       "      <td>-0.336343</td>\n",
       "      <td>-0.128640</td>\n",
       "      <td>-0.272865</td>\n",
       "      <td>0.151891</td>\n",
       "      <td>-0.141799</td>\n",
       "      <td>0.161796</td>\n",
       "      <td>-0.075188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039959</td>\n",
       "      <td>0.229610</td>\n",
       "      <td>0.049388</td>\n",
       "      <td>0.244578</td>\n",
       "      <td>-0.055200</td>\n",
       "      <td>0.514541</td>\n",
       "      <td>0.139084</td>\n",
       "      <td>-0.193043</td>\n",
       "      <td>-0.010445</td>\n",
       "      <td>0.225701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>-0.134108</td>\n",
       "      <td>-0.142738</td>\n",
       "      <td>0.077398</td>\n",
       "      <td>-0.052656</td>\n",
       "      <td>-0.223050</td>\n",
       "      <td>-0.024748</td>\n",
       "      <td>0.051775</td>\n",
       "      <td>0.225418</td>\n",
       "      <td>0.016313</td>\n",
       "      <td>0.203651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153466</td>\n",
       "      <td>0.119594</td>\n",
       "      <td>0.041444</td>\n",
       "      <td>-0.234165</td>\n",
       "      <td>0.024491</td>\n",
       "      <td>-0.309568</td>\n",
       "      <td>0.324702</td>\n",
       "      <td>-0.276497</td>\n",
       "      <td>-0.004959</td>\n",
       "      <td>-0.320971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>-0.195736</td>\n",
       "      <td>-0.387907</td>\n",
       "      <td>0.320228</td>\n",
       "      <td>0.165131</td>\n",
       "      <td>-0.110947</td>\n",
       "      <td>-0.112957</td>\n",
       "      <td>0.218435</td>\n",
       "      <td>0.383855</td>\n",
       "      <td>-0.047947</td>\n",
       "      <td>0.187719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206781</td>\n",
       "      <td>-0.097978</td>\n",
       "      <td>-0.012083</td>\n",
       "      <td>-0.240991</td>\n",
       "      <td>0.008867</td>\n",
       "      <td>-0.388769</td>\n",
       "      <td>0.221236</td>\n",
       "      <td>-0.012026</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>-0.178799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>-0.175762</td>\n",
       "      <td>-0.019424</td>\n",
       "      <td>-0.084928</td>\n",
       "      <td>-0.072786</td>\n",
       "      <td>-0.068806</td>\n",
       "      <td>-0.081929</td>\n",
       "      <td>-0.045627</td>\n",
       "      <td>0.274146</td>\n",
       "      <td>0.235335</td>\n",
       "      <td>0.114931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280163</td>\n",
       "      <td>0.069029</td>\n",
       "      <td>0.146151</td>\n",
       "      <td>-0.255648</td>\n",
       "      <td>-0.111431</td>\n",
       "      <td>-0.251150</td>\n",
       "      <td>0.245139</td>\n",
       "      <td>-0.012150</td>\n",
       "      <td>0.026396</td>\n",
       "      <td>-0.624170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0.094857</td>\n",
       "      <td>-0.019395</td>\n",
       "      <td>0.125970</td>\n",
       "      <td>-0.028764</td>\n",
       "      <td>-0.241570</td>\n",
       "      <td>-0.020699</td>\n",
       "      <td>-0.032222</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.209894</td>\n",
       "      <td>0.165685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239647</td>\n",
       "      <td>0.025610</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>-0.043390</td>\n",
       "      <td>-0.004722</td>\n",
       "      <td>0.162544</td>\n",
       "      <td>-0.059068</td>\n",
       "      <td>0.221578</td>\n",
       "      <td>0.111782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>-0.105337</td>\n",
       "      <td>-0.107708</td>\n",
       "      <td>0.436254</td>\n",
       "      <td>0.082409</td>\n",
       "      <td>-0.188900</td>\n",
       "      <td>-0.016179</td>\n",
       "      <td>0.376869</td>\n",
       "      <td>0.374280</td>\n",
       "      <td>-0.006386</td>\n",
       "      <td>0.114953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002830</td>\n",
       "      <td>-0.114155</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>-0.373506</td>\n",
       "      <td>-0.156187</td>\n",
       "      <td>-0.331361</td>\n",
       "      <td>0.123601</td>\n",
       "      <td>0.148411</td>\n",
       "      <td>-0.275720</td>\n",
       "      <td>-0.343218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "1619 -0.504543 -0.238862  0.268207 -0.195398 -0.129295 -0.071738 -0.071930   \n",
       "1620 -0.476096 -0.214239 -0.063099 -0.076593 -0.299466 -0.026293 -0.101854   \n",
       "1621 -0.110859  0.055071 -0.044472 -0.087786 -0.168676  0.216177  0.356343   \n",
       "1622 -0.505651 -0.113361  0.225261 -0.311196  0.022356 -0.122159  0.551452   \n",
       "1623 -0.285427 -0.194134  0.210919 -0.336343 -0.128640 -0.272865  0.151891   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2019 -0.134108 -0.142738  0.077398 -0.052656 -0.223050 -0.024748  0.051775   \n",
       "2020 -0.195736 -0.387907  0.320228  0.165131 -0.110947 -0.112957  0.218435   \n",
       "2021 -0.175762 -0.019424 -0.084928 -0.072786 -0.068806 -0.081929 -0.045627   \n",
       "2022  0.094857 -0.019395  0.125970 -0.028764 -0.241570 -0.020699 -0.032222   \n",
       "2023 -0.105337 -0.107708  0.436254  0.082409 -0.188900 -0.016179  0.376869   \n",
       "\n",
       "       embed_7   embed_8   embed_9  ...  embed_758  embed_759  embed_760  \\\n",
       "1619 -0.078853  0.193799  0.312561  ...  -0.078656  -0.016189   0.005497   \n",
       "1620  0.181612 -0.097852  0.107278  ...  -0.084571   0.052774   0.167772   \n",
       "1621  0.203279 -0.012863 -0.026753  ...   0.165248   0.271330   0.153580   \n",
       "1622 -0.142533  0.048752  0.323749  ...  -0.121238   0.069174   0.016471   \n",
       "1623 -0.141799  0.161796 -0.075188  ...  -0.039959   0.229610   0.049388   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "2019  0.225418  0.016313  0.203651  ...  -0.153466   0.119594   0.041444   \n",
       "2020  0.383855 -0.047947  0.187719  ...   0.206781  -0.097978  -0.012083   \n",
       "2021  0.274146  0.235335  0.114931  ...  -0.280163   0.069029   0.146151   \n",
       "2022  0.003480  0.209894  0.165685  ...  -0.239647   0.025610  -0.003960   \n",
       "2023  0.374280 -0.006386  0.114953  ...  -0.002830  -0.114155   0.166000   \n",
       "\n",
       "      embed_761  embed_762  embed_763  embed_764  embed_765  embed_766  \\\n",
       "1619   0.196333  -0.178815   0.025027  -0.060292  -0.433548   0.046218   \n",
       "1620   0.129893  -0.125352  -0.338464   0.123560  -0.251659   0.034861   \n",
       "1621  -0.144125  -0.126144  -0.044800   0.281531   0.094203   0.042266   \n",
       "1622   0.303918  -0.078248   0.339804   0.009332  -0.463689  -0.051655   \n",
       "1623   0.244578  -0.055200   0.514541   0.139084  -0.193043  -0.010445   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2019  -0.234165   0.024491  -0.309568   0.324702  -0.276497  -0.004959   \n",
       "2020  -0.240991   0.008867  -0.388769   0.221236  -0.012026   0.026120   \n",
       "2021  -0.255648  -0.111431  -0.251150   0.245139  -0.012150   0.026396   \n",
       "2022   0.016724  -0.043390  -0.004722   0.162544  -0.059068   0.221578   \n",
       "2023  -0.373506  -0.156187  -0.331361   0.123601   0.148411  -0.275720   \n",
       "\n",
       "      embed_767  \n",
       "1619   0.099468  \n",
       "1620  -0.264190  \n",
       "1621   0.203444  \n",
       "1622   0.500953  \n",
       "1623   0.225701  \n",
       "...         ...  \n",
       "2019  -0.320971  \n",
       "2020  -0.178799  \n",
       "2021  -0.624170  \n",
       "2022   0.111782  \n",
       "2023  -0.343218  \n",
       "\n",
       "[405 rows x 768 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1619, 768) (1619, 39) (405, 768) (405, 39)\n",
      "(2024, 768) (2024, 39)\n"
     ]
    }
   ],
   "source": [
    "print(bert_x_train.shape,bert_y_train.shape,bert_x_val.shape,bert_y_val.shape)\n",
    "print(bert_x.shape,bert_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renuk\\anaconda3\\envs\\harbar\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:18] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:40:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:40:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:40:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:40:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:41:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:41:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:41:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:41:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:41:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:41:58] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:42:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:42:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:42:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:42:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:42:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:43:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:43:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:43:21] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:43:30] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:43:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:43:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:43:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:44:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:44:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:44:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:44:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:44:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:45:02] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:45:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:45:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:45:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:45:45] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:45:56] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:46:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:46:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:46:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:46:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:46:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Mean Absolute Error for each collumn: [1.13074348e+00 9.14404004e-01 1.21494558e+00 1.24950234e+00\n",
      " 9.59702848e-01 1.22227403e+00 5.25231840e-03 1.23304323e-02\n",
      " 1.64517408e-02 2.93229055e-01 2.92626535e-01 2.97871763e-01\n",
      " 4.04674834e-02 8.54225907e-02 1.19774545e-01 2.96387294e-02\n",
      " 5.83619191e-02 8.41905533e-02 3.17719377e-02 6.64552621e-02\n",
      " 9.80730918e-02 2.26784833e-02 4.91280363e-02 7.04558849e-02\n",
      " 2.98028820e+01 4.47004164e+01 6.05261650e+01 1.37637239e+01\n",
      " 2.06278095e+01 2.95648139e+01 3.43723996e-01 9.58138911e-01\n",
      " 1.27886717e+00 1.98009840e-01 2.88547707e-01 3.77051893e-01\n",
      " 2.48358517e+00 5.80421500e+00 6.57707591e+00]\n",
      "Mean of mae: 5.786173816758452\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "bert_model = XGBRegressor(n_estimators=100,max_depth = 5,learning_rate = 0.1, subsample = 0.7, colsample_bytree = 0.8, scoring = 'neg_mean_squared_error') #16695.37712703339\n",
    "# Your code here\n",
    "\n",
    "multioutputregressor = MultiOutputRegressor(bert_model)\n",
    "# Fit the model\n",
    "multioutputregressor.fit(bert_x_train,bert_y_train) # Your code here\n",
    "\n",
    "# Get predictions\n",
    "bert_predictions = multioutputregressor.predict(bert_x_val)# Your code here\n",
    "\n",
    "# Calculate MAE\n",
    "error = mae(bert_predictions,bert_y_val,multioutput='raw_values') # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error for each collumn:\" , error)\n",
    "print(f\"Mean of mae: {np.mean(error)}\")\n",
    "\n",
    "# Check your answer\n",
    "#step_2.check()\n",
    "#LR: 1= 1116.448, 0.01 = 480.97, 0.1 = 333.445\n",
    "#n_est: 10 = 487.954, 100 = 333.445, 1000 = 333.424\n",
    "#max_depth: 10 = 340.772, 5 = 333.445, 1 = 356.496\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-25T22:47:58.984986Z",
     "iopub.status.busy": "2022-12-25T22:47:58.984511Z",
     "iopub.status.idle": "2022-12-25T22:47:59.066463Z",
     "shell.execute_reply": "2022-12-25T22:47:59.065486Z",
     "shell.execute_reply.started": "2022-12-25T22:47:58.984939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8.085426296839545\n"
     ]
    }
   ],
   "source": [
    "# Calculate mse\n",
    "error = mse(bert_predictions,bert_y_val,squared = False) # Your code here\n",
    "\n",
    "# Uncomment to print MSE\n",
    "print(\"Mean Squared Error:\" , error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renuk\\anaconda3\\envs\\harbar\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:04:58] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:05:08] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:05:18] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:05:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:05:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:05:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:06:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:06:08] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:06:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:06:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:06:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:06:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:07:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:07:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:07:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:07:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:07:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:07:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:07:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:08:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:08:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:08:34] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:08:44] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:08:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:09:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:09:14] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:09:25] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:09:37] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:09:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:09:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:10:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:10:19] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:10:31] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:10:41] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:10:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:11:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:11:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:11:21] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:11:32] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "bert_model = XGBRegressor(n_estimators=100,max_depth = 5,learning_rate = 0.1, subsample = 0.7, colsample_bytree = 0.8, scoring = 'neg_mean_squared_error') #16695.37712703339\n",
    "# Your code here\n",
    "\n",
    "multioutputregressor = MultiOutputRegressor(bert_model)\n",
    "# Fit the model\n",
    "multioutputregressor.fit(bert_x_train,bert_y_train) # Your code here\n",
    "\n",
    "# Get predictions\n",
    "bert_predictions = multioutputregressor.predict(bert_x_test)# Your code here\n",
    "\n",
    "final_df = pd.DataFrame(bert_predictions)\n",
    "\n",
    "\n",
    "# Calculate MAE\n",
    "#error = mae(bert_predictions,bert_y_val,multioutput='raw_values') # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "#print(\"Mean Absolute Error for each collumn:\" , error)\n",
    "#print(f\"Mean of mae: {np.mean(error)}\")\n",
    "\n",
    "# Check your answer\n",
    "#step_2.check()\n",
    "#LR: 1= 1116.448, 0.01 = 480.97, 0.1 = 333.445\n",
    "#n_est: 10 = 487.954, 100 = 333.445, 1000 = 333.424\n",
    "#max_depth: 10 = 340.772, 5 = 333.445, 1 = 356.496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(bert_predictions)\n",
    "final_df.columns = bert_y.columns\n",
    "final_df.to_csv('final_submission_normal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renuk\\AppData\\Local\\Temp\\ipykernel_50040\\2864669567.py:9: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(\"seaborn-whitegrid\")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "\n",
    "def plot_variance(pca, width=8, dpi=100):\n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    n = pca.n_components_\n",
    "    grid = np.arange(1, n + 1)\n",
    "    # Explained variance\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    axs[0].bar(grid, evr)\n",
    "    axs[0].set(\n",
    "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
    "    )\n",
    "    # Cumulative Variance\n",
    "    cv = np.cumsum(evr)\n",
    "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
    "    axs[1].set(\n",
    "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
    "    )\n",
    "    # Set up figure\n",
    "    fig.set(figwidth=8, dpi=100)\n",
    "    return axs\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "df = bert_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_758</th>\n",
       "      <th>embed_759</th>\n",
       "      <th>embed_760</th>\n",
       "      <th>embed_761</th>\n",
       "      <th>embed_762</th>\n",
       "      <th>embed_763</th>\n",
       "      <th>embed_764</th>\n",
       "      <th>embed_765</th>\n",
       "      <th>embed_766</th>\n",
       "      <th>embed_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.132859</td>\n",
       "      <td>0.235927</td>\n",
       "      <td>-1.003491</td>\n",
       "      <td>-0.385945</td>\n",
       "      <td>0.927168</td>\n",
       "      <td>0.091525</td>\n",
       "      <td>-1.047246</td>\n",
       "      <td>-1.408046</td>\n",
       "      <td>-0.817942</td>\n",
       "      <td>2.572402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601924</td>\n",
       "      <td>-1.612896</td>\n",
       "      <td>0.390153</td>\n",
       "      <td>1.023965</td>\n",
       "      <td>0.317982</td>\n",
       "      <td>-0.034866</td>\n",
       "      <td>0.300078</td>\n",
       "      <td>-1.774429</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.370231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.819700</td>\n",
       "      <td>-0.582502</td>\n",
       "      <td>-0.397459</td>\n",
       "      <td>1.123959</td>\n",
       "      <td>1.131245</td>\n",
       "      <td>-0.378241</td>\n",
       "      <td>-0.508434</td>\n",
       "      <td>1.956197</td>\n",
       "      <td>-0.749808</td>\n",
       "      <td>-0.910111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.998827</td>\n",
       "      <td>0.232715</td>\n",
       "      <td>-0.882578</td>\n",
       "      <td>-2.714823</td>\n",
       "      <td>-1.618681</td>\n",
       "      <td>-1.380771</td>\n",
       "      <td>0.242622</td>\n",
       "      <td>1.991049</td>\n",
       "      <td>-0.289781</td>\n",
       "      <td>-0.445619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.216888</td>\n",
       "      <td>-1.587361</td>\n",
       "      <td>2.010357</td>\n",
       "      <td>0.584568</td>\n",
       "      <td>1.470084</td>\n",
       "      <td>-0.584895</td>\n",
       "      <td>-0.455226</td>\n",
       "      <td>1.431938</td>\n",
       "      <td>-1.630935</td>\n",
       "      <td>-0.249087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701508</td>\n",
       "      <td>1.153062</td>\n",
       "      <td>-0.612544</td>\n",
       "      <td>-1.330411</td>\n",
       "      <td>-0.810849</td>\n",
       "      <td>-1.381573</td>\n",
       "      <td>-0.265321</td>\n",
       "      <td>1.362785</td>\n",
       "      <td>0.059910</td>\n",
       "      <td>-0.725743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.591983</td>\n",
       "      <td>1.742447</td>\n",
       "      <td>0.090673</td>\n",
       "      <td>0.378965</td>\n",
       "      <td>0.317660</td>\n",
       "      <td>-1.434233</td>\n",
       "      <td>-1.859474</td>\n",
       "      <td>-0.645377</td>\n",
       "      <td>-1.928874</td>\n",
       "      <td>-0.617804</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.723199</td>\n",
       "      <td>-0.351788</td>\n",
       "      <td>-0.230554</td>\n",
       "      <td>1.119867</td>\n",
       "      <td>1.302416</td>\n",
       "      <td>1.200930</td>\n",
       "      <td>-2.644221</td>\n",
       "      <td>-0.586728</td>\n",
       "      <td>-0.083352</td>\n",
       "      <td>0.530201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.658860</td>\n",
       "      <td>-0.128480</td>\n",
       "      <td>0.146593</td>\n",
       "      <td>0.056112</td>\n",
       "      <td>0.315045</td>\n",
       "      <td>-0.759516</td>\n",
       "      <td>-0.225942</td>\n",
       "      <td>-0.496355</td>\n",
       "      <td>-0.135506</td>\n",
       "      <td>-0.455858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022115</td>\n",
       "      <td>-1.147587</td>\n",
       "      <td>0.618487</td>\n",
       "      <td>0.986228</td>\n",
       "      <td>0.432324</td>\n",
       "      <td>1.260486</td>\n",
       "      <td>-0.757462</td>\n",
       "      <td>-0.920205</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.030697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.647018</td>\n",
       "      <td>-0.393823</td>\n",
       "      <td>-0.719694</td>\n",
       "      <td>0.356353</td>\n",
       "      <td>-0.522268</td>\n",
       "      <td>-0.007321</td>\n",
       "      <td>-0.511127</td>\n",
       "      <td>0.622422</td>\n",
       "      <td>-0.447320</td>\n",
       "      <td>0.511957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403905</td>\n",
       "      <td>0.469110</td>\n",
       "      <td>0.323866</td>\n",
       "      <td>-0.796405</td>\n",
       "      <td>1.051328</td>\n",
       "      <td>-0.899965</td>\n",
       "      <td>1.087617</td>\n",
       "      <td>-0.240870</td>\n",
       "      <td>0.100192</td>\n",
       "      <td>-1.127444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.408448</td>\n",
       "      <td>-2.373868</td>\n",
       "      <td>1.005086</td>\n",
       "      <td>1.417626</td>\n",
       "      <td>0.278708</td>\n",
       "      <td>-0.662587</td>\n",
       "      <td>0.484542</td>\n",
       "      <td>1.236761</td>\n",
       "      <td>-0.868483</td>\n",
       "      <td>0.416301</td>\n",
       "      <td>...</td>\n",
       "      <td>1.898143</td>\n",
       "      <td>-0.951415</td>\n",
       "      <td>-0.047188</td>\n",
       "      <td>-0.821020</td>\n",
       "      <td>0.931331</td>\n",
       "      <td>-1.163624</td>\n",
       "      <td>0.510832</td>\n",
       "      <td>0.817070</td>\n",
       "      <td>0.304292</td>\n",
       "      <td>-0.609914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.485769</td>\n",
       "      <td>0.602093</td>\n",
       "      <td>-1.872669</td>\n",
       "      <td>0.258261</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.432095</td>\n",
       "      <td>-1.093030</td>\n",
       "      <td>0.811364</td>\n",
       "      <td>0.988146</td>\n",
       "      <td>-0.020705</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.213526</td>\n",
       "      <td>0.138977</td>\n",
       "      <td>1.049710</td>\n",
       "      <td>-0.873876</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-0.705490</td>\n",
       "      <td>0.644083</td>\n",
       "      <td>0.816572</td>\n",
       "      <td>0.306107</td>\n",
       "      <td>-2.231138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>1.533358</td>\n",
       "      <td>0.602324</td>\n",
       "      <td>-0.374698</td>\n",
       "      <td>0.472779</td>\n",
       "      <td>-0.654592</td>\n",
       "      <td>0.022757</td>\n",
       "      <td>-1.012948</td>\n",
       "      <td>-0.238135</td>\n",
       "      <td>0.821407</td>\n",
       "      <td>0.284017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.954622</td>\n",
       "      <td>-0.144508</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.108343</td>\n",
       "      <td>0.529980</td>\n",
       "      <td>0.114865</td>\n",
       "      <td>0.183648</td>\n",
       "      <td>0.628892</td>\n",
       "      <td>1.587869</td>\n",
       "      <td>0.447851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>0.758394</td>\n",
       "      <td>-0.110911</td>\n",
       "      <td>1.829194</td>\n",
       "      <td>1.014521</td>\n",
       "      <td>-0.278265</td>\n",
       "      <td>0.056337</td>\n",
       "      <td>1.431060</td>\n",
       "      <td>1.199631</td>\n",
       "      <td>-0.596091</td>\n",
       "      <td>-0.020574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558684</td>\n",
       "      <td>-1.057032</td>\n",
       "      <td>1.187305</td>\n",
       "      <td>-1.298892</td>\n",
       "      <td>-0.336332</td>\n",
       "      <td>-0.972512</td>\n",
       "      <td>-0.033441</td>\n",
       "      <td>1.458850</td>\n",
       "      <td>-1.677895</td>\n",
       "      <td>-1.208425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2024 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0    -1.132859  0.235927 -1.003491 -0.385945  0.927168  0.091525 -1.047246   \n",
       "1     0.819700 -0.582502 -0.397459  1.123959  1.131245 -0.378241 -0.508434   \n",
       "2     1.216888 -1.587361  2.010357  0.584568  1.470084 -0.584895 -0.455226   \n",
       "3    -0.591983  1.742447  0.090673  0.378965  0.317660 -1.434233 -1.859474   \n",
       "4    -0.658860 -0.128480  0.146593  0.056112  0.315045 -0.759516 -0.225942   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2019  0.647018 -0.393823 -0.719694  0.356353 -0.522268 -0.007321 -0.511127   \n",
       "2020  0.408448 -2.373868  1.005086  1.417626  0.278708 -0.662587  0.484542   \n",
       "2021  0.485769  0.602093 -1.872669  0.258261  0.579810 -0.432095 -1.093030   \n",
       "2022  1.533358  0.602324 -0.374698  0.472779 -0.654592  0.022757 -1.012948   \n",
       "2023  0.758394 -0.110911  1.829194  1.014521 -0.278265  0.056337  1.431060   \n",
       "\n",
       "       embed_7   embed_8   embed_9  ...  embed_758  embed_759  embed_760  \\\n",
       "0    -1.408046 -0.817942  2.572402  ...  -0.601924  -1.612896   0.390153   \n",
       "1     1.956197 -0.749808 -0.910111  ...  -0.998827   0.232715  -0.882578   \n",
       "2     1.431938 -1.630935 -0.249087  ...   0.701508   1.153062  -0.612544   \n",
       "3    -0.645377 -1.928874 -0.617804  ...  -1.723199  -0.351788  -0.230554   \n",
       "4    -0.496355 -0.135506 -0.455858  ...   0.022115  -1.147587   0.618487   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "2019  0.622422 -0.447320  0.511957  ...  -0.403905   0.469110   0.323866   \n",
       "2020  1.236761 -0.868483  0.416301  ...   1.898143  -0.951415  -0.047188   \n",
       "2021  0.811364  0.988146 -0.020705  ...  -1.213526   0.138977   1.049710   \n",
       "2022 -0.238135  0.821407  0.284017  ...  -0.954622  -0.144508   0.009117   \n",
       "2023  1.199631 -0.596091 -0.020574  ...   0.558684  -1.057032   1.187305   \n",
       "\n",
       "      embed_761  embed_762  embed_763  embed_764  embed_765  embed_766  \\\n",
       "0      1.023965   0.317982  -0.034866   0.300078  -1.774429   0.692929   \n",
       "1     -2.714823  -1.618681  -1.380771   0.242622   1.991049  -0.289781   \n",
       "2     -1.330411  -0.810849  -1.381573  -0.265321   1.362785   0.059910   \n",
       "3      1.119867   1.302416   1.200930  -2.644221  -0.586728  -0.083352   \n",
       "4      0.986228   0.432324   1.260486  -0.757462  -0.920205   0.015907   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2019  -0.796405   1.051328  -0.899965   1.087617  -0.240870   0.100192   \n",
       "2020  -0.821020   0.931331  -1.163624   0.510832   0.817070   0.304292   \n",
       "2021  -0.873876   0.007406  -0.705490   0.644083   0.816572   0.306107   \n",
       "2022   0.108343   0.529980   0.114865   0.183648   0.628892   1.587869   \n",
       "2023  -1.298892  -0.336332  -0.972512  -0.033441   1.458850  -1.677895   \n",
       "\n",
       "      embed_767  \n",
       "0      0.370231  \n",
       "1     -0.445619  \n",
       "2     -0.725743  \n",
       "3      0.530201  \n",
       "4      0.030697  \n",
       "...         ...  \n",
       "2019  -1.127444  \n",
       "2020  -0.609914  \n",
       "2021  -2.231138  \n",
       "2022   0.447851  \n",
       "2023  -1.208425  \n",
       "\n",
       "[2024 rows x 768 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.copy()\n",
    "# Standardize\n",
    "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC759</th>\n",
       "      <th>PC760</th>\n",
       "      <th>PC761</th>\n",
       "      <th>PC762</th>\n",
       "      <th>PC763</th>\n",
       "      <th>PC764</th>\n",
       "      <th>PC765</th>\n",
       "      <th>PC766</th>\n",
       "      <th>PC767</th>\n",
       "      <th>PC768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.932579</td>\n",
       "      <td>7.329417</td>\n",
       "      <td>-2.751820</td>\n",
       "      <td>1.568235</td>\n",
       "      <td>-0.988746</td>\n",
       "      <td>-8.319196</td>\n",
       "      <td>0.369681</td>\n",
       "      <td>-0.936013</td>\n",
       "      <td>2.602728</td>\n",
       "      <td>3.039498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073868</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>-0.080470</td>\n",
       "      <td>-0.062773</td>\n",
       "      <td>-0.002626</td>\n",
       "      <td>0.015221</td>\n",
       "      <td>-0.007353</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>-0.008472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.256109</td>\n",
       "      <td>1.160300</td>\n",
       "      <td>3.044332</td>\n",
       "      <td>5.445784</td>\n",
       "      <td>0.928240</td>\n",
       "      <td>6.439400</td>\n",
       "      <td>-2.993410</td>\n",
       "      <td>-5.782405</td>\n",
       "      <td>-1.293003</td>\n",
       "      <td>4.396071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044982</td>\n",
       "      <td>0.165225</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.029255</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>-0.022694</td>\n",
       "      <td>0.019825</td>\n",
       "      <td>-0.006647</td>\n",
       "      <td>0.021453</td>\n",
       "      <td>-0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.554393</td>\n",
       "      <td>6.167798</td>\n",
       "      <td>-5.181880</td>\n",
       "      <td>-3.939465</td>\n",
       "      <td>-6.062320</td>\n",
       "      <td>4.199193</td>\n",
       "      <td>-3.427514</td>\n",
       "      <td>-1.499892</td>\n",
       "      <td>2.985803</td>\n",
       "      <td>-4.586354</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005592</td>\n",
       "      <td>-0.045352</td>\n",
       "      <td>0.123459</td>\n",
       "      <td>0.162576</td>\n",
       "      <td>-0.040528</td>\n",
       "      <td>0.033749</td>\n",
       "      <td>0.015356</td>\n",
       "      <td>0.093140</td>\n",
       "      <td>-0.024002</td>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.769701</td>\n",
       "      <td>8.001141</td>\n",
       "      <td>-1.243169</td>\n",
       "      <td>-7.658419</td>\n",
       "      <td>-8.109180</td>\n",
       "      <td>-5.270768</td>\n",
       "      <td>1.168275</td>\n",
       "      <td>-3.003094</td>\n",
       "      <td>-0.559164</td>\n",
       "      <td>-2.577336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017576</td>\n",
       "      <td>0.025144</td>\n",
       "      <td>-0.051896</td>\n",
       "      <td>-0.005026</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>-0.057172</td>\n",
       "      <td>0.035462</td>\n",
       "      <td>-0.008540</td>\n",
       "      <td>-0.011897</td>\n",
       "      <td>-0.011945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.276059</td>\n",
       "      <td>8.233653</td>\n",
       "      <td>-7.937291</td>\n",
       "      <td>1.966330</td>\n",
       "      <td>2.668436</td>\n",
       "      <td>-2.865685</td>\n",
       "      <td>-5.123681</td>\n",
       "      <td>4.219050</td>\n",
       "      <td>-2.528761</td>\n",
       "      <td>-4.128568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030663</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>0.083009</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.087520</td>\n",
       "      <td>-0.037655</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.080913</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>-0.003609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>-9.776784</td>\n",
       "      <td>7.656981</td>\n",
       "      <td>-0.383178</td>\n",
       "      <td>3.233537</td>\n",
       "      <td>0.573768</td>\n",
       "      <td>-0.396051</td>\n",
       "      <td>0.932863</td>\n",
       "      <td>-1.323615</td>\n",
       "      <td>-0.392267</td>\n",
       "      <td>-2.792933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045847</td>\n",
       "      <td>0.108590</td>\n",
       "      <td>0.034041</td>\n",
       "      <td>-0.033642</td>\n",
       "      <td>-0.078081</td>\n",
       "      <td>-0.028919</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>-0.008000</td>\n",
       "      <td>-0.008123</td>\n",
       "      <td>-0.002937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>-11.573339</td>\n",
       "      <td>-0.505984</td>\n",
       "      <td>-2.392889</td>\n",
       "      <td>-4.928123</td>\n",
       "      <td>-8.457326</td>\n",
       "      <td>0.712204</td>\n",
       "      <td>-3.230417</td>\n",
       "      <td>3.640116</td>\n",
       "      <td>4.956814</td>\n",
       "      <td>-2.349592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>-0.016134</td>\n",
       "      <td>-0.049131</td>\n",
       "      <td>-0.021317</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>-0.039677</td>\n",
       "      <td>0.034051</td>\n",
       "      <td>0.102813</td>\n",
       "      <td>-0.027205</td>\n",
       "      <td>0.022590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>-11.642615</td>\n",
       "      <td>4.392670</td>\n",
       "      <td>1.181121</td>\n",
       "      <td>1.385690</td>\n",
       "      <td>-2.297541</td>\n",
       "      <td>-1.017546</td>\n",
       "      <td>-1.283799</td>\n",
       "      <td>0.642947</td>\n",
       "      <td>-5.460137</td>\n",
       "      <td>2.281579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043959</td>\n",
       "      <td>-0.021854</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>-0.032240</td>\n",
       "      <td>0.023254</td>\n",
       "      <td>-0.017986</td>\n",
       "      <td>0.050919</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.096125</td>\n",
       "      <td>0.009457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>-4.384442</td>\n",
       "      <td>-1.080695</td>\n",
       "      <td>-1.352720</td>\n",
       "      <td>-5.156963</td>\n",
       "      <td>-0.277219</td>\n",
       "      <td>1.814832</td>\n",
       "      <td>-0.079863</td>\n",
       "      <td>8.373806</td>\n",
       "      <td>2.952255</td>\n",
       "      <td>8.703587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051001</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>0.038884</td>\n",
       "      <td>0.025406</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>-0.069819</td>\n",
       "      <td>-0.013707</td>\n",
       "      <td>-0.014963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>-13.022389</td>\n",
       "      <td>2.948730</td>\n",
       "      <td>2.659598</td>\n",
       "      <td>-0.087885</td>\n",
       "      <td>-0.234380</td>\n",
       "      <td>2.847314</td>\n",
       "      <td>-5.640284</td>\n",
       "      <td>-4.108105</td>\n",
       "      <td>-0.292018</td>\n",
       "      <td>-4.346104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040962</td>\n",
       "      <td>-0.040559</td>\n",
       "      <td>0.044513</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.039155</td>\n",
       "      <td>0.029492</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>-0.024134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2024 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0      3.932579  7.329417 -2.751820  1.568235 -0.988746 -8.319196  0.369681   \n",
       "1    -17.256109  1.160300  3.044332  5.445784  0.928240  6.439400 -2.993410   \n",
       "2    -16.554393  6.167798 -5.181880 -3.939465 -6.062320  4.199193 -3.427514   \n",
       "3      7.769701  8.001141 -1.243169 -7.658419 -8.109180 -5.270768  1.168275   \n",
       "4      7.276059  8.233653 -7.937291  1.966330  2.668436 -2.865685 -5.123681   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "2019  -9.776784  7.656981 -0.383178  3.233537  0.573768 -0.396051  0.932863   \n",
       "2020 -11.573339 -0.505984 -2.392889 -4.928123 -8.457326  0.712204 -3.230417   \n",
       "2021 -11.642615  4.392670  1.181121  1.385690 -2.297541 -1.017546 -1.283799   \n",
       "2022  -4.384442 -1.080695 -1.352720 -5.156963 -0.277219  1.814832 -0.079863   \n",
       "2023 -13.022389  2.948730  2.659598 -0.087885 -0.234380  2.847314 -5.640284   \n",
       "\n",
       "           PC8       PC9      PC10  ...     PC759     PC760     PC761  \\\n",
       "0    -0.936013  2.602728  3.039498  ... -0.073868  0.010621  0.012393   \n",
       "1    -5.782405 -1.293003  4.396071  ...  0.044982  0.165225  0.000147   \n",
       "2    -1.499892  2.985803 -4.586354  ... -0.005592 -0.045352  0.123459   \n",
       "3    -3.003094 -0.559164 -2.577336  ... -0.017576  0.025144 -0.051896   \n",
       "4     4.219050 -2.528761 -4.128568  ...  0.030663  0.017088  0.083009   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2019 -1.323615 -0.392267 -2.792933  ... -0.045847  0.108590  0.034041   \n",
       "2020  3.640116  4.956814 -2.349592  ...  0.013008 -0.016134 -0.049131   \n",
       "2021  0.642947 -5.460137  2.281579  ...  0.043959 -0.021854  0.011969   \n",
       "2022  8.373806  2.952255  8.703587  ... -0.051001  0.023040  0.038884   \n",
       "2023 -4.108105 -0.292018 -4.346104  ...  0.040962 -0.040559  0.044513   \n",
       "\n",
       "         PC762     PC763     PC764     PC765     PC766     PC767     PC768  \n",
       "0    -0.080470 -0.062773 -0.002626  0.015221 -0.007353  0.006455 -0.008472  \n",
       "1    -0.029255 -0.002971 -0.022694  0.019825 -0.006647  0.021453 -0.001482  \n",
       "2     0.162576 -0.040528  0.033749  0.015356  0.093140 -0.024002  0.002430  \n",
       "3    -0.005026  0.016323 -0.057172  0.035462 -0.008540 -0.011897 -0.011945  \n",
       "4     0.004754  0.087520 -0.037655  0.004708  0.080913  0.018860 -0.003609  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2019 -0.033642 -0.078081 -0.028919 -0.047905 -0.008000 -0.008123 -0.002937  \n",
       "2020 -0.021317  0.012974 -0.039677  0.034051  0.102813 -0.027205  0.022590  \n",
       "2021 -0.032240  0.023254 -0.017986  0.050919  0.007248  0.096125  0.009457  \n",
       "2022  0.025406  0.015830  0.009743  0.005124 -0.069819 -0.013707 -0.014963  \n",
       "2023  0.005954  0.012512  0.039155  0.029492 -0.042335  0.136600 -0.024134  \n",
       "\n",
       "[2024 rows x 768 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create principal components\n",
    "pca = PCA(n_components = 768)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Convert to dataframe\n",
    "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC759</th>\n",
       "      <th>PC760</th>\n",
       "      <th>PC761</th>\n",
       "      <th>PC762</th>\n",
       "      <th>PC763</th>\n",
       "      <th>PC764</th>\n",
       "      <th>PC765</th>\n",
       "      <th>PC766</th>\n",
       "      <th>PC767</th>\n",
       "      <th>PC768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>embed_0</th>\n",
       "      <td>-0.071264</td>\n",
       "      <td>-0.013447</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>0.010703</td>\n",
       "      <td>-0.017508</td>\n",
       "      <td>0.027870</td>\n",
       "      <td>-0.041065</td>\n",
       "      <td>0.036139</td>\n",
       "      <td>0.021589</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064807</td>\n",
       "      <td>-0.021799</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.069729</td>\n",
       "      <td>0.041310</td>\n",
       "      <td>-0.010661</td>\n",
       "      <td>-0.129586</td>\n",
       "      <td>-0.013226</td>\n",
       "      <td>-0.080841</td>\n",
       "      <td>-0.036325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_1</th>\n",
       "      <td>-0.002313</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>0.021504</td>\n",
       "      <td>-0.002578</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>-0.003664</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>-0.036411</td>\n",
       "      <td>-0.082832</td>\n",
       "      <td>-0.012285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020114</td>\n",
       "      <td>-0.008795</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>-0.012634</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>-0.027643</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.010697</td>\n",
       "      <td>-0.023722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_2</th>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.044613</td>\n",
       "      <td>-0.033442</td>\n",
       "      <td>-0.040395</td>\n",
       "      <td>-0.008392</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>-0.027877</td>\n",
       "      <td>-0.037728</td>\n",
       "      <td>0.026993</td>\n",
       "      <td>-0.071286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042722</td>\n",
       "      <td>-0.025484</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>-0.036509</td>\n",
       "      <td>-0.002701</td>\n",
       "      <td>-0.010558</td>\n",
       "      <td>0.035742</td>\n",
       "      <td>-0.032770</td>\n",
       "      <td>-0.017559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_3</th>\n",
       "      <td>-0.063614</td>\n",
       "      <td>-0.010072</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>-0.022170</td>\n",
       "      <td>-0.051140</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>-0.014315</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>-0.021392</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007314</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>-0.016455</td>\n",
       "      <td>-0.006445</td>\n",
       "      <td>0.049048</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.030704</td>\n",
       "      <td>0.039555</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>-0.047179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_4</th>\n",
       "      <td>-0.005764</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>-0.058925</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>0.043203</td>\n",
       "      <td>-0.022454</td>\n",
       "      <td>0.054920</td>\n",
       "      <td>-0.062927</td>\n",
       "      <td>0.010469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036687</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>-0.015072</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>-0.004973</td>\n",
       "      <td>0.029980</td>\n",
       "      <td>0.021540</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>-0.035338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_763</th>\n",
       "      <td>0.069731</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>-0.038800</td>\n",
       "      <td>-0.012346</td>\n",
       "      <td>0.069912</td>\n",
       "      <td>-0.026265</td>\n",
       "      <td>-0.022738</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>-0.013029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084920</td>\n",
       "      <td>-0.167732</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>-0.010689</td>\n",
       "      <td>-0.096995</td>\n",
       "      <td>0.166054</td>\n",
       "      <td>-0.032746</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>-0.092625</td>\n",
       "      <td>0.015394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_764</th>\n",
       "      <td>-0.041379</td>\n",
       "      <td>-0.045619</td>\n",
       "      <td>-0.013781</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.045491</td>\n",
       "      <td>-0.044980</td>\n",
       "      <td>0.026536</td>\n",
       "      <td>-0.015502</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>-0.024860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041579</td>\n",
       "      <td>-0.071737</td>\n",
       "      <td>-0.038851</td>\n",
       "      <td>0.032381</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>0.043958</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>-0.004124</td>\n",
       "      <td>0.034585</td>\n",
       "      <td>-0.048378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_765</th>\n",
       "      <td>-0.076734</td>\n",
       "      <td>-0.022830</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>-0.011763</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>0.063528</td>\n",
       "      <td>-0.015568</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>-0.003272</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>-0.065914</td>\n",
       "      <td>-0.066619</td>\n",
       "      <td>0.066716</td>\n",
       "      <td>0.111469</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.009140</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.019004</td>\n",
       "      <td>-0.065532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_766</th>\n",
       "      <td>0.007927</td>\n",
       "      <td>-0.042533</td>\n",
       "      <td>-0.007151</td>\n",
       "      <td>-0.012111</td>\n",
       "      <td>-0.032052</td>\n",
       "      <td>-0.001781</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>0.080412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031182</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.025819</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>-0.003172</td>\n",
       "      <td>-0.023589</td>\n",
       "      <td>-0.010943</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>-0.028218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_767</th>\n",
       "      <td>0.072717</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>-0.032598</td>\n",
       "      <td>-0.022940</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>-0.032861</td>\n",
       "      <td>-0.024260</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.032436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088728</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>-0.124652</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>-0.027711</td>\n",
       "      <td>-0.021413</td>\n",
       "      <td>-0.022893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
       "embed_0   -0.071264 -0.013447  0.034943  0.010703 -0.017508  0.027870   \n",
       "embed_1   -0.002313 -0.009770  0.021504 -0.002578 -0.002046 -0.003664   \n",
       "embed_2    0.005949  0.044613 -0.033442 -0.040395 -0.008392  0.021941   \n",
       "embed_3   -0.063614 -0.010072  0.006761 -0.022170 -0.051140  0.043547   \n",
       "embed_4   -0.005764  0.010870 -0.058925  0.017393  0.013293  0.043203   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "embed_763  0.069731  0.001394 -0.038800 -0.012346  0.069912 -0.026265   \n",
       "embed_764 -0.041379 -0.045619 -0.013781  0.004738  0.045491 -0.044980   \n",
       "embed_765 -0.076734 -0.022830  0.011302 -0.011763  0.010939  0.063528   \n",
       "embed_766  0.007927 -0.042533 -0.007151 -0.012111 -0.032052 -0.001781   \n",
       "embed_767  0.072717  0.002287 -0.032598 -0.022940  0.024752 -0.032861   \n",
       "\n",
       "                PC7       PC8       PC9      PC10  ...     PC759     PC760  \\\n",
       "embed_0   -0.041065  0.036139  0.021589  0.009141  ...  0.064807 -0.021799   \n",
       "embed_1    0.014121 -0.036411 -0.082832 -0.012285  ...  0.020114 -0.008795   \n",
       "embed_2   -0.027877 -0.037728  0.026993 -0.071286  ... -0.042722 -0.025484   \n",
       "embed_3   -0.014315  0.011731 -0.021392  0.031417  ...  0.007314  0.004989   \n",
       "embed_4   -0.022454  0.054920 -0.062927  0.010469  ... -0.036687  0.006368   \n",
       "...             ...       ...       ...       ...  ...       ...       ...   \n",
       "embed_763 -0.022738  0.016637 -0.004296 -0.013029  ...  0.084920 -0.167732   \n",
       "embed_764  0.026536 -0.015502  0.024366 -0.024860  ...  0.041579 -0.071737   \n",
       "embed_765 -0.015568  0.015632 -0.003272  0.002525  ...  0.008217 -0.065914   \n",
       "embed_766  0.059603  0.028530  0.008068  0.080412  ... -0.031182  0.021839   \n",
       "embed_767 -0.024260 -0.021246  0.004804  0.032436  ...  0.088728  0.003470   \n",
       "\n",
       "              PC761     PC762     PC763     PC764     PC765     PC766  \\\n",
       "embed_0    0.009693  0.069729  0.041310 -0.010661 -0.129586 -0.013226   \n",
       "embed_1    0.008272 -0.012634  0.006413  0.005847 -0.027643  0.006962   \n",
       "embed_2    0.020562  0.014664 -0.036509 -0.002701 -0.010558  0.035742   \n",
       "embed_3   -0.016455 -0.006445  0.049048  0.001261  0.030704  0.039555   \n",
       "embed_4   -0.015072  0.008923  0.006543 -0.004973  0.029980  0.021540   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "embed_763  0.169014 -0.010689 -0.096995  0.166054 -0.032746  0.140699   \n",
       "embed_764 -0.038851  0.032381  0.013299  0.043958  0.007048 -0.004124   \n",
       "embed_765 -0.066619  0.066716  0.111469 -0.003097 -0.009140  0.051531   \n",
       "embed_766  0.008214  0.025819  0.010751 -0.003172 -0.023589 -0.010943   \n",
       "embed_767  0.001966  0.018982 -0.124652  0.011554  0.013344 -0.027711   \n",
       "\n",
       "              PC767     PC768  \n",
       "embed_0   -0.080841 -0.036325  \n",
       "embed_1    0.010697 -0.023722  \n",
       "embed_2   -0.032770 -0.017559  \n",
       "embed_3    0.006731 -0.047179  \n",
       "embed_4    0.018703 -0.035338  \n",
       "...             ...       ...  \n",
       "embed_763 -0.092625  0.015394  \n",
       "embed_764  0.034585 -0.048378  \n",
       "embed_765  0.019004 -0.065532  \n",
       "embed_766 -0.019630 -0.028218  \n",
       "embed_767 -0.021413 -0.022893  \n",
       "\n",
       "[768 rows x 768 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,  # transpose the matrix of loadings\n",
    "    columns=component_names,  # so the columns are the principal components\n",
    "    index=X.columns,  # and the rows are the original features\n",
    ")\n",
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent of Variance explained by each of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual variance contributions:\n",
      "PCA_0:0.1536021506856803\n",
      "PCA_1:0.058351161949277114\n",
      "PCA_2:0.04781489684212397\n",
      "PCA_3:0.03936577875556931\n",
      "PCA_4:0.03881880619354415\n",
      "PCA_5:0.03126309799975222\n",
      "PCA_6:0.027488945174873148\n",
      "PCA_7:0.021227917722217583\n",
      "PCA_8:0.0208059456624421\n",
      "PCA_9:0.01681845795186435\n",
      "PCA_10:0.014808527713263034\n",
      "PCA_11:0.014482075370848032\n",
      "PCA_12:0.013986754044277764\n",
      "PCA_13:0.012879782104239748\n",
      "PCA_14:0.012224742407386208\n",
      "PCA_15:0.011801402479708267\n",
      "PCA_16:0.010825207014737735\n",
      "PCA_17:0.010592824921636141\n",
      "PCA_18:0.009656782598705638\n",
      "PCA_19:0.009303899069784323\n",
      "PCA_20:0.008857389761543908\n",
      "PCA_21:0.008399982768213693\n",
      "PCA_22:0.008029342463084791\n",
      "PCA_23:0.0079180081537864\n",
      "PCA_24:0.007408017680001944\n",
      "PCA_25:0.00725866934383627\n",
      "PCA_26:0.007177797490658531\n",
      "PCA_27:0.006533027962465239\n",
      "PCA_28:0.006394499467536697\n",
      "PCA_29:0.006166058896865074\n",
      "PCA_30:0.006082765450447249\n",
      "PCA_31:0.005813602611953874\n",
      "PCA_32:0.0056322599752156415\n",
      "PCA_33:0.005590126053383434\n",
      "PCA_34:0.005403186188882221\n",
      "PCA_35:0.005310012313058401\n",
      "PCA_36:0.005116242395283573\n",
      "PCA_37:0.005015184228124155\n",
      "PCA_38:0.004966176453004455\n",
      "PCA_39:0.004814741407714114\n",
      "PCA_40:0.004652081945252638\n",
      "PCA_41:0.004565095434187455\n",
      "PCA_42:0.004447418760998524\n",
      "PCA_43:0.004313848442699281\n",
      "PCA_44:0.004272152764087034\n",
      "PCA_45:0.004139251386185879\n",
      "PCA_46:0.004121813807231679\n",
      "PCA_47:0.004098588785038244\n",
      "PCA_48:0.00394578306494029\n",
      "PCA_49:0.0037650330448140445\n",
      "PCA_50:0.003741946635181565\n",
      "PCA_51:0.0035480250651857503\n",
      "PCA_52:0.0034887857259823904\n",
      "PCA_53:0.003442537432837083\n",
      "PCA_54:0.003342172332007823\n",
      "PCA_55:0.003274173604677814\n",
      "PCA_56:0.003226926914795274\n",
      "PCA_57:0.0031727667024735798\n",
      "PCA_58:0.003159364817749752\n",
      "PCA_59:0.0030755686174150656\n",
      "PCA_60:0.0029807266445534743\n",
      "PCA_61:0.0029144449256472953\n",
      "PCA_62:0.00289946241176339\n",
      "PCA_63:0.002878178802954482\n",
      "PCA_64:0.0028553533384794937\n",
      "PCA_65:0.002775924014384602\n",
      "PCA_66:0.002743803397607149\n",
      "PCA_67:0.0026553662701661934\n",
      "PCA_68:0.002633828764983281\n",
      "PCA_69:0.0026127398142224275\n",
      "PCA_70:0.002602630337554732\n",
      "PCA_71:0.0025458777386357834\n",
      "PCA_72:0.002500463158137299\n",
      "PCA_73:0.002438218453472206\n",
      "PCA_74:0.0024053017235603383\n",
      "PCA_75:0.0023910259545488004\n",
      "PCA_76:0.0023258381910759335\n",
      "PCA_77:0.002299903114799391\n",
      "PCA_78:0.002250503051524425\n",
      "PCA_79:0.0022230158239064913\n",
      "PCA_80:0.002192284966348895\n",
      "PCA_81:0.0021485118591787933\n",
      "PCA_82:0.002100557894688974\n",
      "PCA_83:0.0020703989804115846\n",
      "PCA_84:0.0020600071932307244\n",
      "PCA_85:0.002018169683311768\n",
      "PCA_86:0.0019645932826431634\n",
      "PCA_87:0.0019241189457283733\n",
      "PCA_88:0.0019084051672155478\n",
      "PCA_89:0.0018482199875614691\n",
      "PCA_90:0.0018316619861623135\n",
      "PCA_91:0.0018171105173078515\n",
      "PCA_92:0.0017788194079906602\n",
      "PCA_93:0.0017538134534703879\n",
      "PCA_94:0.0017464879791103593\n",
      "PCA_95:0.0016854381204549395\n",
      "PCA_96:0.00163982550122502\n",
      "PCA_97:0.001628427027227843\n",
      "PCA_98:0.0015902490556549908\n",
      "PCA_99:0.0015838344087618383\n",
      "PCA_100:0.001574272315065672\n",
      "PCA_101:0.001543536135707307\n",
      "PCA_102:0.0015343166701062686\n",
      "PCA_103:0.0015098571371408701\n",
      "PCA_104:0.0014935686266118347\n",
      "PCA_105:0.001461606041367013\n",
      "PCA_106:0.0014368605926709424\n",
      "PCA_107:0.0014277033987106465\n",
      "PCA_108:0.0014011940179164072\n",
      "PCA_109:0.0013959363337857223\n",
      "PCA_110:0.0013596401760718494\n",
      "PCA_111:0.0013421133860276122\n",
      "PCA_112:0.0013151048300861327\n",
      "PCA_113:0.0012910408258114737\n",
      "PCA_114:0.001263799411971714\n",
      "PCA_115:0.001243918135592762\n",
      "PCA_116:0.0012321401117693156\n",
      "PCA_117:0.001217898914237371\n",
      "PCA_118:0.001174613477323043\n",
      "PCA_119:0.0011594271020488889\n",
      "PCA_120:0.0011400533899981894\n",
      "PCA_121:0.0011285573310937497\n",
      "PCA_122:0.0011163759765601957\n",
      "PCA_123:0.0011061524648939094\n",
      "PCA_124:0.0010920030892245533\n",
      "PCA_125:0.0010782790585957345\n",
      "PCA_126:0.0010652067060824453\n",
      "PCA_127:0.0010467477233809953\n",
      "PCA_128:0.0010333881911166432\n",
      "PCA_129:0.0010192604010945188\n",
      "PCA_130:0.0009915317131133905\n",
      "PCA_131:0.0009722538309982056\n",
      "PCA_132:0.0009672667286213967\n",
      "PCA_133:0.0009624601131108935\n",
      "PCA_134:0.0009497201977165851\n",
      "PCA_135:0.0009321846461587303\n",
      "PCA_136:0.0009177515940836929\n",
      "PCA_137:0.0009145852993093191\n",
      "PCA_138:0.0009026954586382205\n",
      "PCA_139:0.0008838190478263103\n",
      "PCA_140:0.0008740367438230621\n",
      "PCA_141:0.000861176187915613\n",
      "PCA_142:0.0008449811209433337\n",
      "PCA_143:0.0008360983551866391\n",
      "PCA_144:0.0008272601120080067\n",
      "PCA_145:0.0008245772641409263\n",
      "PCA_146:0.0008055224158854283\n",
      "PCA_147:0.0007903060744394678\n",
      "PCA_148:0.0007805488302631077\n",
      "PCA_149:0.0007771212902268246\n",
      "PCA_150:0.0007635249385651408\n",
      "PCA_151:0.0007400164173404396\n",
      "PCA_152:0.0007330609855088192\n",
      "PCA_153:0.0007292496264762313\n",
      "PCA_154:0.0007264625883330546\n",
      "PCA_155:0.0007061015321151842\n",
      "PCA_156:0.0006995094711194868\n",
      "PCA_157:0.0006969193528419517\n",
      "PCA_158:0.000679965968075073\n",
      "PCA_159:0.0006741310834805644\n",
      "PCA_160:0.0006689131015277631\n",
      "PCA_161:0.0006546969099968994\n",
      "PCA_162:0.0006511064317400497\n",
      "PCA_163:0.0006416168844371537\n",
      "PCA_164:0.0006341220970421358\n",
      "PCA_165:0.0006266474547512788\n",
      "PCA_166:0.0006260859327856653\n",
      "PCA_167:0.0006148836966257791\n",
      "PCA_168:0.0006100364874454019\n",
      "PCA_169:0.0005965023433356706\n",
      "PCA_170:0.0005868114922920629\n",
      "PCA_171:0.0005769168500089687\n",
      "PCA_172:0.000572095861567013\n",
      "PCA_173:0.0005689638712833238\n",
      "PCA_174:0.0005623673940220763\n",
      "PCA_175:0.000552570167724783\n",
      "PCA_176:0.0005493190361834807\n",
      "PCA_177:0.0005407274237323153\n",
      "PCA_178:0.0005344247377708514\n",
      "PCA_179:0.000518765991524469\n",
      "PCA_180:0.0005139179642020809\n",
      "PCA_181:0.0005054535409178221\n",
      "PCA_182:0.0005048996040385878\n",
      "PCA_183:0.0004979561483175869\n",
      "PCA_184:0.0004951581250940958\n",
      "PCA_185:0.00048919315479055\n",
      "PCA_186:0.00048061312967571175\n",
      "PCA_187:0.00047430799593922024\n",
      "PCA_188:0.0004677681721208021\n",
      "PCA_189:0.00046569042881314574\n",
      "PCA_190:0.0004560902165105965\n",
      "PCA_191:0.0004538329990260046\n",
      "PCA_192:0.00044960053092822205\n",
      "PCA_193:0.000444696867506298\n",
      "PCA_194:0.0004388565098590398\n",
      "PCA_195:0.0004370326142022787\n",
      "PCA_196:0.00042951633115980814\n",
      "PCA_197:0.0004266322185977521\n",
      "PCA_198:0.0004246149101706712\n",
      "PCA_199:0.00041897357006904487\n",
      "PCA_200:0.00041629512935264623\n",
      "PCA_201:0.0004117160569626029\n",
      "PCA_202:0.00040596695026370465\n",
      "PCA_203:0.0004027778220278168\n",
      "PCA_204:0.0003986193671238766\n",
      "PCA_205:0.00039166065273012413\n",
      "PCA_206:0.0003879370537883215\n",
      "PCA_207:0.0003865689363303553\n",
      "PCA_208:0.0003831102859955357\n",
      "PCA_209:0.00037776585659336234\n",
      "PCA_210:0.0003725192908228428\n",
      "PCA_211:0.00036762071598565665\n",
      "PCA_212:0.00036590853611876144\n",
      "PCA_213:0.0003597728529703034\n",
      "PCA_214:0.000354880814210465\n",
      "PCA_215:0.000349607646321106\n",
      "PCA_216:0.0003454687648887872\n",
      "PCA_217:0.00034118609884892833\n",
      "PCA_218:0.00034052393841129867\n",
      "PCA_219:0.000336166340120855\n",
      "PCA_220:0.0003321633248854403\n",
      "PCA_221:0.00032946644275277264\n",
      "PCA_222:0.0003264229941961691\n",
      "PCA_223:0.0003244981763982871\n",
      "PCA_224:0.00031787456672934975\n",
      "PCA_225:0.00031670470133877515\n",
      "PCA_226:0.00031324163179210753\n",
      "PCA_227:0.0003106310649622841\n",
      "PCA_228:0.00030857291375006597\n",
      "PCA_229:0.00030691267665450067\n",
      "PCA_230:0.0002997039027286377\n",
      "PCA_231:0.00029922691144898967\n",
      "PCA_232:0.00029830181574293403\n",
      "PCA_233:0.0002924407209021571\n",
      "PCA_234:0.0002893393456476661\n",
      "PCA_235:0.0002865548638691147\n",
      "PCA_236:0.0002819079308229965\n",
      "PCA_237:0.00028162850408989935\n",
      "PCA_238:0.00027725598789128414\n",
      "PCA_239:0.0002767968278697608\n",
      "PCA_240:0.0002736812292546916\n",
      "PCA_241:0.0002702715101436481\n",
      "PCA_242:0.00026813558952787744\n",
      "PCA_243:0.000264060045795429\n",
      "PCA_244:0.00026056292135793807\n",
      "PCA_245:0.00025805079328299025\n",
      "PCA_246:0.00025478774407354266\n",
      "PCA_247:0.0002544561107305752\n",
      "PCA_248:0.0002498272248772147\n",
      "PCA_249:0.00024911342601805593\n",
      "PCA_250:0.0002471341404005692\n",
      "PCA_251:0.00024255663082014514\n",
      "PCA_252:0.00024214703774927613\n",
      "PCA_253:0.00024010684830600475\n",
      "PCA_254:0.00023908318874544005\n",
      "PCA_255:0.00023840329118517305\n",
      "PCA_256:0.000233114274208291\n",
      "PCA_257:0.00023175306278629308\n",
      "PCA_258:0.0002311478615310423\n",
      "PCA_259:0.00022725153282537828\n",
      "PCA_260:0.00022530629136314554\n",
      "PCA_261:0.0002235101821292985\n",
      "PCA_262:0.00022102977625417487\n",
      "PCA_263:0.0002204912321446456\n",
      "PCA_264:0.0002180805567533323\n",
      "PCA_265:0.00021695437489387367\n",
      "PCA_266:0.00021324150716451365\n",
      "PCA_267:0.00021065213991003338\n",
      "PCA_268:0.00021013177354778083\n",
      "PCA_269:0.00020811516833884653\n",
      "PCA_270:0.0002038232141035566\n",
      "PCA_271:0.00020266868770363168\n",
      "PCA_272:0.00020141056175998587\n",
      "PCA_273:0.0001977028731718378\n",
      "PCA_274:0.0001972384640472684\n",
      "PCA_275:0.00019641771875913955\n",
      "PCA_276:0.00019504403502313273\n",
      "PCA_277:0.0001921950308685458\n",
      "PCA_278:0.00018874534252969795\n",
      "PCA_279:0.0001880859447397246\n",
      "PCA_280:0.00018725458505016107\n",
      "PCA_281:0.00018560058232107776\n",
      "PCA_282:0.00018419887278984116\n",
      "PCA_283:0.00018318152913814523\n",
      "PCA_284:0.00018126829129260424\n",
      "PCA_285:0.00017975831864047443\n",
      "PCA_286:0.00017930400284288001\n",
      "PCA_287:0.0001772442597283852\n",
      "PCA_288:0.0001765005877209897\n",
      "PCA_289:0.00017501104921245126\n",
      "PCA_290:0.00017262922621055278\n",
      "PCA_291:0.0001708885761340934\n",
      "PCA_292:0.0001699972587080942\n",
      "PCA_293:0.00016734547429854708\n",
      "PCA_294:0.0001663524219155633\n",
      "PCA_295:0.00016522633296427787\n",
      "PCA_296:0.00016494675570422892\n",
      "PCA_297:0.00016332982144199982\n",
      "PCA_298:0.00016157349778936683\n",
      "PCA_299:0.00016061350726876827\n",
      "PCA_300:0.0001597411496236165\n",
      "PCA_301:0.00015693014550564394\n",
      "PCA_302:0.0001542696880380951\n",
      "PCA_303:0.00015256536126268344\n",
      "PCA_304:0.00015224012623182487\n",
      "PCA_305:0.0001519109802240795\n",
      "PCA_306:0.0001510935251752889\n",
      "PCA_307:0.00014997938263259695\n",
      "PCA_308:0.00014791318233634148\n",
      "PCA_309:0.00014630682078579672\n",
      "PCA_310:0.00014553986846077175\n",
      "PCA_311:0.00014380050563384686\n",
      "PCA_312:0.00014282872277082353\n",
      "PCA_313:0.0001417925940386943\n",
      "PCA_314:0.0001412712667411596\n",
      "PCA_315:0.0001400648928024632\n",
      "PCA_316:0.00013912089875841148\n",
      "PCA_317:0.00013759614334668768\n",
      "PCA_318:0.00013704620908164635\n",
      "PCA_319:0.00013611311385194376\n",
      "PCA_320:0.00013488429276620529\n",
      "PCA_321:0.00013273953455073497\n",
      "PCA_322:0.00013214898235973564\n",
      "PCA_323:0.0001313000138503987\n",
      "PCA_324:0.0001305504717655384\n",
      "PCA_325:0.00012978052658168556\n",
      "PCA_326:0.0001289797812291841\n",
      "PCA_327:0.0001273383234282561\n",
      "PCA_328:0.00012616713593332056\n",
      "PCA_329:0.00012557521347679598\n",
      "PCA_330:0.00012452306008035004\n",
      "PCA_331:0.00012419745696712225\n",
      "PCA_332:0.0001224587890581091\n",
      "PCA_333:0.00012243828220603713\n",
      "PCA_334:0.00012009458297758993\n",
      "PCA_335:0.00011972048853716977\n",
      "PCA_336:0.00011849307399095601\n",
      "PCA_337:0.00011756391342062078\n",
      "PCA_338:0.00011673656574667346\n",
      "PCA_339:0.00011640392656069867\n",
      "PCA_340:0.00011424612118084051\n",
      "PCA_341:0.00011355906330512118\n",
      "PCA_342:0.00011289913704349624\n",
      "PCA_343:0.0001124024299857569\n",
      "PCA_344:0.00011162274662908008\n",
      "PCA_345:0.00011107747496670572\n",
      "PCA_346:0.00011002116148909758\n",
      "PCA_347:0.00010925790847854172\n",
      "PCA_348:0.00010829266691947998\n",
      "PCA_349:0.00010790150657592947\n",
      "PCA_350:0.00010712556311611675\n",
      "PCA_351:0.00010611202114789174\n",
      "PCA_352:0.00010435744089119434\n",
      "PCA_353:0.00010405141933713354\n",
      "PCA_354:0.00010397766256516222\n",
      "PCA_355:0.00010281210858287065\n",
      "PCA_356:0.0001014980352351555\n",
      "PCA_357:0.00010055041783080388\n"
     ]
    }
   ],
   "source": [
    "print('Individual variance contributions:')\n",
    "n_comp = 768\n",
    "for j in range(n_comp):\n",
    "    if pca.explained_variance_ratio_[j]>(0.0001):\n",
    "        print(f\"PCA_{j}:{pca.explained_variance_ratio_[j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot: title={'center': '% Explained Variance'}, xlabel='Component'>,\n",
       "       <AxesSubplot: title={'center': '% Cumulative Variance'}, xlabel='Component'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_variance(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per the PCA, we will only select the first 500 Principal components since they capture most of the data variation.\n",
    "bert_x_pca = X_pca.iloc[:,0:356]\n",
    "bert_xpca_train,bert_xpca_val,bert_y_train,bert_y_val = train_test_split(bert_x_pca,bert_y,train_size = 0.8,shuffle = False)\n",
    "# 100 = 367.98, 200 = 371.06, 300 = 375.25016, 356 = 368.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1619, 356), (405, 356), (1619, 39), (405, 39))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_xpca_train.shape, bert_xpca_val.shape, bert_y_train.shape, bert_y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model via Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renuk\\anaconda3\\envs\\harbar\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:15:56] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:15:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:15:59] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:01] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:02] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:05] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:07] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:08] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:10] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:15] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:18] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:20] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:22] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:25] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:26] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:28] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:31] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:16:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:34] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:42] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:45] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:52] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:53] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:55] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:16:58] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Mean Absolute Error for each collumn: [1.19618311e+00 1.33904417e+00 1.60111228e+00 1.25103622e+00\n",
      " 1.33635304e+00 1.67675503e+00 5.05426436e-03 1.23031702e-02\n",
      " 1.66048241e-02 2.85456681e-01 4.32765953e-01 4.02803084e-01\n",
      " 4.15902187e-02 8.87353133e-02 1.18959118e-01 3.09269212e-02\n",
      " 5.70544685e-02 8.80571875e-02 3.22542906e-02 6.80116076e-02\n",
      " 9.97774847e-02 2.27760411e-02 4.96678646e-02 7.27181017e-02\n",
      " 3.09673027e+01 4.94802056e+01 6.59981582e+01 1.45720205e+01\n",
      " 2.29087932e+01 3.22560929e+01 3.43308109e-01 1.01480679e+00\n",
      " 1.23803120e+00 2.02837134e-01 3.11992099e-01 4.05737233e-01\n",
      " 2.53058297e+00 5.71528500e+00 6.66474027e+00]\n",
      "Mean of mae: 6.280407549631866\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "bert_model = XGBRegressor(n_estimators=100,max_depth = 5,learning_rate = 0.1, subsample = 0.7, colsample_bytree = 0.8, scoring = 'neg_mean_squared_error') #16695.37712703339\n",
    "# Your code here\n",
    "\n",
    "multioutputregressor = MultiOutputRegressor(bert_model)\n",
    "# Fit the model\n",
    "multioutputregressor.fit(bert_xpca_train,bert_y_train) # Your code here\n",
    "\n",
    "# Get predictions\n",
    "bert_predictions = multioutputregressor.predict(bert_xpca_val)# Your code here\n",
    "\n",
    "# Calculate MAE\n",
    "error = mae(bert_predictions,bert_y_val,multioutput='raw_values') # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error for each collumn:\" , error)\n",
    "print(f\"Mean of mae: {np.mean(error)}\")\n",
    "\n",
    "# Check your answer\n",
    "#step_2.check()\n",
    "#LR: 1= 1116.448, 0.01 = 480.97, 0.1 = 333.445\n",
    "#n_est: 10 = 487.954, 100 = 333.445, 1000 = 333.424\n",
    "#max_depth: 10 = 340.772, 5 = 333.445, 1 = 356.496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 39)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8.87173859168831\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE\n",
    "error = mse(bert_predictions,bert_y_val,squared = False) # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Squared Error:\" , error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renuk\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "C:\\Users\\renuk\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 14.173868  ,  -2.8631666 ,  -2.442157  ],\n",
       "       [-20.44047   ,  24.068691  , -26.820168  ],\n",
       "       [-11.001228  ,  30.94191   ,  16.934595  ],\n",
       "       ...,\n",
       "       [-22.545082  ,  30.246454  ,   0.54643977],\n",
       "       [ -7.4642067 ,  34.83593   ,  38.305206  ],\n",
       "       [ -2.7085426 ,  22.54281   , -34.389935  ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standarized_data = StandardScaler().fit_transform(bert_x)\n",
    "model = TSNE(n_components=3, random_state=0,perplexity=300, n_iter=5000)\n",
    "tsne_data = model.fit_transform(standarized_data)\n",
    "tsne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1619, 3), (405, 3), (1619, 39), (405, 39))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_xtsne_train,bert_xtsne_val,bert_y_train,bert_y_val = train_test_split(tsne_data,bert_y,train_size = 0.8,random_state = 1)\n",
    "bert_xtsne_train.shape, bert_xtsne_val.shape, bert_y_train.shape, bert_y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:23:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:23:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:23:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Mean Absolute Error for each collumn: [1.19478862e+00 2.34381351e+00 2.92277338e+00 1.16293030e+00\n",
      " 2.37811003e+00 3.07263384e+00 5.19261062e-03 1.27233357e-02\n",
      " 1.89840800e-02 2.97120313e-01 6.11738292e-01 8.57732015e-01\n",
      " 4.12646901e-02 9.61487216e-02 1.31683740e-01 3.09846787e-02\n",
      " 6.55648551e-02 8.45892974e-02 3.18696715e-02 7.39280638e-02\n",
      " 9.81454752e-02 2.17810233e-02 5.53015988e-02 7.31437075e-02\n",
      " 2.84600761e+01 6.02733160e+01 8.31426460e+01 1.39066598e+01\n",
      " 2.95420991e+01 4.12817946e+01 3.08830459e-01 1.00575948e+00\n",
      " 1.24755635e+00 1.86594901e-01 4.00781061e-01 5.46947464e-01\n",
      " 2.55932742e+00 6.16308174e+00 7.25432301e+00]\n",
      "Mean of mae: 7.4862240872728485\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "bert_model = XGBRegressor(n_estimators=100,max_depth = 5,learning_rate = 0.1, subsample = 0.7, colsample_bytree = 0.8, scoring = 'neg_mean_squared_error') #16695.37712703339\n",
    "# Your code here\n",
    "\n",
    "multioutputregressor = MultiOutputRegressor(bert_model)\n",
    "# Fit the model\n",
    "multioutputregressor.fit(bert_xtsne_train,bert_y_train) # Your code here\n",
    "\n",
    "# Get predictions\n",
    "bert_predictions = multioutputregressor.predict(bert_xtsne_val)# Your code here\n",
    "\n",
    "# Calculate MAE\n",
    "error = mae(bert_predictions,bert_y_val,multioutput='raw_values') # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error for each collumn:\" , error)\n",
    "print(f\"Mean of mae: {np.mean(error)}\")\n",
    "\n",
    "# Check your answer\n",
    "#step_2.check()\n",
    "#LR: 1= 1116.448, 0.01 = 480.97, 0.1 = 333.445\n",
    "#n_est: 10 = 487.954, 100 = 333.445, 1000 = 333.424\n",
    "#max_depth: 10 = 340.772, 5 = 333.445, 1 = 356.496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 10.410023659709722\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE\n",
    "error = mse(bert_predictions,bert_y_val,squared = False) # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Squared Error:\" , error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a final submission after doing the feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual variance contributions:\n",
      "PCA_0:0.16094318150830933\n",
      "PCA_1:0.06920581564615247\n",
      "PCA_2:0.06000326516397064\n",
      "PCA_3:0.04093293141602898\n",
      "PCA_4:0.03989382100995152\n",
      "PCA_5:0.03240482261903217\n",
      "PCA_6:0.028258100494854003\n",
      "PCA_7:0.02397404267356519\n",
      "PCA_8:0.019572882581297527\n",
      "PCA_9:0.018556125497287638\n",
      "PCA_10:0.017636088054593647\n",
      "PCA_11:0.015282525420235426\n",
      "PCA_12:0.014578376341957492\n",
      "PCA_13:0.014231887696992586\n",
      "PCA_14:0.012679308106009753\n",
      "PCA_15:0.011577257595629227\n",
      "PCA_16:0.01135197426335047\n",
      "PCA_17:0.010575312956668739\n",
      "PCA_18:0.009900777082104314\n",
      "PCA_19:0.009759447386183718\n",
      "PCA_20:0.00929600036230121\n",
      "PCA_21:0.008625086201322633\n",
      "PCA_22:0.008281613801232823\n",
      "PCA_23:0.007980709581364868\n",
      "PCA_24:0.007826311318246945\n",
      "PCA_25:0.007397439243302276\n",
      "PCA_26:0.0072676805821751045\n",
      "PCA_27:0.00698424247996524\n",
      "PCA_28:0.006916521191706617\n",
      "PCA_29:0.006543840049250633\n",
      "PCA_30:0.006215565113468008\n",
      "PCA_31:0.006109953303382062\n",
      "PCA_32:0.005916229808545003\n",
      "PCA_33:0.005767767209654851\n",
      "PCA_34:0.005622354517315324\n",
      "PCA_35:0.005453138930747925\n",
      "PCA_36:0.0053782626790891295\n",
      "PCA_37:0.005072298887548043\n",
      "PCA_38:0.0049966457413593394\n",
      "PCA_39:0.004912562149124105\n",
      "PCA_40:0.004686167124647724\n",
      "PCA_41:0.004531426784424296\n",
      "PCA_42:0.004476231905287629\n",
      "PCA_43:0.004254890367824056\n",
      "PCA_44:0.004169913970242738\n",
      "PCA_45:0.004138463772393681\n",
      "PCA_46:0.004040217060778003\n",
      "PCA_47:0.004026163602347962\n",
      "PCA_48:0.003931852891314838\n",
      "PCA_49:0.003807774574231443\n",
      "PCA_50:0.0037275613094582675\n",
      "PCA_51:0.0036701524584153446\n",
      "PCA_52:0.0035990467981623503\n",
      "PCA_53:0.0035084664306553304\n",
      "PCA_54:0.0034496862756954786\n",
      "PCA_55:0.0032705868589179687\n",
      "PCA_56:0.003215364296192046\n",
      "PCA_57:0.003135425363281651\n",
      "PCA_58:0.003112616253896352\n",
      "PCA_59:0.0030573410298955403\n",
      "PCA_60:0.0029737230836996953\n",
      "PCA_61:0.002947086801740286\n",
      "PCA_62:0.0028616779707149815\n",
      "PCA_63:0.0028148500741349385\n",
      "PCA_64:0.002783891055267587\n",
      "PCA_65:0.0026518745075129685\n",
      "PCA_66:0.002631381712108839\n",
      "PCA_67:0.0025970018814199937\n",
      "PCA_68:0.0025210065833712846\n",
      "PCA_69:0.002452794296461495\n",
      "PCA_70:0.0024077392599886954\n",
      "PCA_71:0.002390428766235629\n",
      "PCA_72:0.002316847280322711\n",
      "PCA_73:0.002256217186664218\n",
      "PCA_74:0.0022012884867846374\n",
      "PCA_75:0.002151551317755997\n",
      "PCA_76:0.0021462791169301193\n",
      "PCA_77:0.002113235412895312\n",
      "PCA_78:0.002074114796223057\n",
      "PCA_79:0.002002699028926404\n",
      "PCA_80:0.001981977575213486\n",
      "PCA_81:0.0019330106678779255\n",
      "PCA_82:0.001896936546265234\n",
      "PCA_83:0.0018778619188714917\n",
      "PCA_84:0.0018556664393967958\n",
      "PCA_85:0.0018357635978346794\n",
      "PCA_86:0.0018023399284296142\n",
      "PCA_87:0.0017607600341289914\n",
      "PCA_88:0.0017208494492789476\n",
      "PCA_89:0.0016389464596227655\n",
      "PCA_90:0.0016198541966003467\n",
      "PCA_91:0.0016000591305656675\n",
      "PCA_92:0.001582472679121127\n",
      "PCA_93:0.0015319411229906287\n",
      "PCA_94:0.0015174581682226842\n",
      "PCA_95:0.0014817705899298223\n",
      "PCA_96:0.0014688012364807144\n",
      "PCA_97:0.0014454603665666093\n",
      "PCA_98:0.0014104344880043764\n",
      "PCA_99:0.0014037086256984987\n",
      "PCA_100:0.0013308378171758496\n",
      "PCA_101:0.0013144683480375986\n",
      "PCA_102:0.0013013224498954067\n",
      "PCA_103:0.0012840779966446273\n",
      "PCA_104:0.0012519990901879213\n",
      "PCA_105:0.001239072040820715\n",
      "PCA_106:0.001231356813230321\n",
      "PCA_107:0.0012105156482751275\n",
      "PCA_108:0.0011891269024902735\n",
      "PCA_109:0.0011673642128017026\n",
      "PCA_110:0.0011434699453151994\n",
      "PCA_111:0.0011199020990974226\n",
      "PCA_112:0.0011007401380817693\n",
      "PCA_113:0.001085585700697263\n",
      "PCA_114:0.0010702136780406531\n",
      "PCA_115:0.0010573218321639729\n",
      "PCA_116:0.0010158100261957689\n",
      "PCA_117:0.0010119527960898444\n",
      "PCA_118:0.0010012317207429924\n",
      "PCA_119:0.0009843426545211855\n",
      "PCA_120:0.0009652221482309596\n",
      "PCA_121:0.0009518180947295143\n",
      "PCA_122:0.0009340353341211683\n",
      "PCA_123:0.0009323007668030893\n",
      "PCA_124:0.0009253437606038063\n",
      "PCA_125:0.0008899293236869472\n",
      "PCA_126:0.0008785472303814166\n",
      "PCA_127:0.0008553422595608894\n",
      "PCA_128:0.0008507929843535754\n",
      "PCA_129:0.0008331687671160867\n",
      "PCA_130:0.0008249210466240487\n",
      "PCA_131:0.0008129588572041287\n",
      "PCA_132:0.0007967778953490577\n",
      "PCA_133:0.0007886600923634171\n",
      "PCA_134:0.0007871528569857449\n",
      "PCA_135:0.0007727048975252411\n",
      "PCA_136:0.000761168455438157\n",
      "PCA_137:0.0007158618263629372\n",
      "PCA_138:0.0007130463148996536\n",
      "PCA_139:0.0007078508880716264\n",
      "PCA_140:0.0006990919888153182\n",
      "PCA_141:0.0006959719202695475\n",
      "PCA_142:0.0006823463015550985\n",
      "PCA_143:0.0006682098054041164\n",
      "PCA_144:0.000662043543863453\n",
      "PCA_145:0.0006551652478663246\n",
      "PCA_146:0.000650656523720858\n",
      "PCA_147:0.0006413038683268677\n",
      "PCA_148:0.0006148846753433092\n",
      "PCA_149:0.0006110867588459566\n",
      "PCA_150:0.0006064657528613897\n",
      "PCA_151:0.0005853550870720169\n",
      "PCA_152:0.0005780443664925258\n",
      "PCA_153:0.0005638784153261925\n",
      "PCA_154:0.0005592152086371029\n",
      "PCA_155:0.0005577739752990378\n",
      "PCA_156:0.0005441608328956761\n",
      "PCA_157:0.0005436697358099168\n",
      "PCA_158:0.0005359788993944962\n",
      "PCA_159:0.0005204429619364601\n",
      "PCA_160:0.0005160076436937802\n",
      "PCA_161:0.0005014774335820792\n",
      "PCA_162:0.0004959103581753296\n",
      "PCA_163:0.000492982697923776\n",
      "PCA_164:0.0004913658604749485\n",
      "PCA_165:0.0004794628892722049\n",
      "PCA_166:0.0004728335796829687\n",
      "PCA_167:0.0004695814694552628\n",
      "PCA_168:0.0004651041244705902\n",
      "PCA_169:0.00045448358396582783\n",
      "PCA_170:0.00045183764014854086\n",
      "PCA_171:0.0004452754528378545\n",
      "PCA_172:0.00043104083003936574\n",
      "PCA_173:0.0004233849641979592\n",
      "PCA_174:0.00041860598663335705\n",
      "PCA_175:0.0004175798754170892\n",
      "PCA_176:0.0004114420180996017\n",
      "PCA_177:0.0004002287397018076\n",
      "PCA_178:0.0003950764998401222\n",
      "PCA_179:0.00039362704791752896\n",
      "PCA_180:0.00038488069514179123\n",
      "PCA_181:0.00037884092128838366\n",
      "PCA_182:0.00037528965921568915\n",
      "PCA_183:0.0003723306273915012\n",
      "PCA_184:0.000366407743422684\n",
      "PCA_185:0.0003594206613760188\n",
      "PCA_186:0.0003555733985924416\n",
      "PCA_187:0.0003498379119301535\n",
      "PCA_188:0.00033898307417098284\n",
      "PCA_189:0.0003342476034634698\n",
      "PCA_190:0.00032788819388932634\n",
      "PCA_191:0.00032681562928607333\n",
      "PCA_192:0.0003174714881829932\n",
      "PCA_193:0.00031544286587826246\n",
      "PCA_194:0.00030987493551299977\n",
      "PCA_195:0.00030244162912065653\n",
      "PCA_196:0.0002986050740351122\n",
      "PCA_197:0.0002950212906069277\n",
      "PCA_198:0.00028984025997174945\n",
      "PCA_199:0.0002893155118345578\n",
      "PCA_200:0.00028504966415302625\n",
      "PCA_201:0.00028216116331411636\n",
      "PCA_202:0.0002770963607619978\n",
      "PCA_203:0.00027315401610460735\n",
      "PCA_204:0.00027129501794300343\n",
      "PCA_205:0.00027002979999006754\n",
      "PCA_206:0.00026460622657433066\n",
      "PCA_207:0.0002615094199028319\n",
      "PCA_208:0.00025731160047592845\n",
      "PCA_209:0.0002543585050839249\n",
      "PCA_210:0.0002507072229714662\n",
      "PCA_211:0.0002483746488623501\n",
      "PCA_212:0.00024486280290932533\n",
      "PCA_213:0.00024379334736285413\n",
      "PCA_214:0.00024129553660267398\n",
      "PCA_215:0.00024047477830877088\n",
      "PCA_216:0.00023537963545656676\n",
      "PCA_217:0.00023457363415246046\n",
      "PCA_218:0.00023102240625324748\n",
      "PCA_219:0.00022703389956486053\n",
      "PCA_220:0.00021884625935834507\n",
      "PCA_221:0.00021595674950584812\n",
      "PCA_222:0.00021513037943063937\n",
      "PCA_223:0.00021086926170985103\n",
      "PCA_224:0.00020904831256382894\n",
      "PCA_225:0.00020428131586880697\n",
      "PCA_226:0.00020012573723980422\n",
      "PCA_227:0.00019840140209617072\n",
      "PCA_228:0.00019717160600508455\n",
      "PCA_229:0.00019615548546328187\n",
      "PCA_230:0.00019051119044417403\n",
      "PCA_231:0.0001870262165005725\n",
      "PCA_232:0.00018489534278398002\n",
      "PCA_233:0.00018343198468950229\n",
      "PCA_234:0.00018102615409073988\n",
      "PCA_235:0.00018017868625713767\n",
      "PCA_236:0.0001765857011442973\n",
      "PCA_237:0.00017397847976441383\n",
      "PCA_238:0.00017338139763426944\n",
      "PCA_239:0.0001712909928012422\n",
      "PCA_240:0.00016862145431301026\n",
      "PCA_241:0.00016688572633617222\n",
      "PCA_242:0.00016377043390022287\n",
      "PCA_243:0.0001619956844803968\n",
      "PCA_244:0.00015913873243260612\n",
      "PCA_245:0.0001573200132657596\n",
      "PCA_246:0.00015625163270434697\n",
      "PCA_247:0.00015170011196293065\n",
      "PCA_248:0.00015134527435194554\n",
      "PCA_249:0.00014830957062159973\n",
      "PCA_250:0.00014729543676807213\n",
      "PCA_251:0.0001466562536324806\n",
      "PCA_252:0.00014387261500138553\n",
      "PCA_253:0.00014050932573916983\n",
      "PCA_254:0.00013855395286831992\n",
      "PCA_255:0.00013651874241749678\n",
      "PCA_256:0.0001354814449363402\n",
      "PCA_257:0.0001338937664472966\n",
      "PCA_258:0.00013183707772301286\n",
      "PCA_259:0.0001298087605270116\n",
      "PCA_260:0.00012825188681013757\n",
      "PCA_261:0.00012475420269780787\n",
      "PCA_262:0.00012384792720151967\n",
      "PCA_263:0.00012228910050691476\n",
      "PCA_264:0.00012109581327864407\n",
      "PCA_265:0.00012026334974775541\n",
      "PCA_266:0.00011805676969334378\n",
      "PCA_267:0.00011703073335338892\n",
      "PCA_268:0.00011546982987510768\n",
      "PCA_269:0.0001134195871576489\n",
      "PCA_270:0.00011268587198316168\n",
      "PCA_271:0.00011062684532845848\n",
      "PCA_272:0.00010852792124950101\n",
      "PCA_273:0.00010756145165653702\n",
      "PCA_274:0.00010509181077756797\n",
      "PCA_275:0.000103820013427999\n",
      "PCA_276:0.00010221410939252659\n",
      "PCA_277:0.00010015128359285224\n"
     ]
    }
   ],
   "source": [
    "test = bert_x_test.copy()\n",
    "# Standardize\n",
    "test_scaled = (test - test.mean(axis=0)) / test.std(axis=0)\n",
    "#test_scaled\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Create principal components\n",
    "pca = PCA(n_components = 415)\n",
    "test_pca = pca.fit_transform(test_scaled)\n",
    "\n",
    "# Convert to dataframe\n",
    "component_names = [f\"PC{i+1}\" for i in range(test_pca.shape[1])]\n",
    "test_pca = pd.DataFrame(test_pca, columns=component_names)\n",
    "\n",
    "#X_pca\n",
    "\n",
    "print('Individual variance contributions:')\n",
    "n_comp = 415\n",
    "for j in range(n_comp):\n",
    "    if pca.explained_variance_ratio_[j]>(0.0001):\n",
    "        print(f\"PCA_{j}:{pca.explained_variance_ratio_[j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'% Explained Variance'}, xlabel='Component'>,\n",
       "       <AxesSubplot:title={'center':'% Cumulative Variance'}, xlabel='Component'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_variance(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC347</th>\n",
       "      <th>PC348</th>\n",
       "      <th>PC349</th>\n",
       "      <th>PC350</th>\n",
       "      <th>PC351</th>\n",
       "      <th>PC352</th>\n",
       "      <th>PC353</th>\n",
       "      <th>PC354</th>\n",
       "      <th>PC355</th>\n",
       "      <th>PC356</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.607536</td>\n",
       "      <td>-1.682347</td>\n",
       "      <td>-7.015973</td>\n",
       "      <td>4.330058</td>\n",
       "      <td>-10.430326</td>\n",
       "      <td>1.448676</td>\n",
       "      <td>-0.339384</td>\n",
       "      <td>-4.611228</td>\n",
       "      <td>-6.788621</td>\n",
       "      <td>0.124128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122797</td>\n",
       "      <td>-0.035993</td>\n",
       "      <td>0.021245</td>\n",
       "      <td>-0.200851</td>\n",
       "      <td>-0.265693</td>\n",
       "      <td>-0.253483</td>\n",
       "      <td>-0.112400</td>\n",
       "      <td>-0.133370</td>\n",
       "      <td>0.304537</td>\n",
       "      <td>-0.063550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.538310</td>\n",
       "      <td>-3.150178</td>\n",
       "      <td>-7.407143</td>\n",
       "      <td>2.021023</td>\n",
       "      <td>-0.004542</td>\n",
       "      <td>-1.633807</td>\n",
       "      <td>1.738065</td>\n",
       "      <td>-2.154232</td>\n",
       "      <td>-1.976465</td>\n",
       "      <td>3.327816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239402</td>\n",
       "      <td>0.223499</td>\n",
       "      <td>0.037284</td>\n",
       "      <td>0.030717</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.119005</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>-0.077573</td>\n",
       "      <td>0.071014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.839628</td>\n",
       "      <td>4.202032</td>\n",
       "      <td>-7.473620</td>\n",
       "      <td>-3.989203</td>\n",
       "      <td>-0.965320</td>\n",
       "      <td>4.723331</td>\n",
       "      <td>4.754412</td>\n",
       "      <td>0.333156</td>\n",
       "      <td>-7.130679</td>\n",
       "      <td>3.160779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138348</td>\n",
       "      <td>-0.121853</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>0.107734</td>\n",
       "      <td>-0.011509</td>\n",
       "      <td>0.166177</td>\n",
       "      <td>-0.009932</td>\n",
       "      <td>-0.237096</td>\n",
       "      <td>-0.168790</td>\n",
       "      <td>0.477852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.981441</td>\n",
       "      <td>-3.859699</td>\n",
       "      <td>7.544679</td>\n",
       "      <td>-9.073383</td>\n",
       "      <td>2.978680</td>\n",
       "      <td>-0.192978</td>\n",
       "      <td>-0.001371</td>\n",
       "      <td>-0.443693</td>\n",
       "      <td>1.448083</td>\n",
       "      <td>-1.900667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010307</td>\n",
       "      <td>0.020917</td>\n",
       "      <td>0.316684</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>0.169967</td>\n",
       "      <td>-0.110248</td>\n",
       "      <td>-0.436463</td>\n",
       "      <td>-0.094482</td>\n",
       "      <td>-0.396167</td>\n",
       "      <td>0.132111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.384403</td>\n",
       "      <td>-3.122986</td>\n",
       "      <td>-8.490395</td>\n",
       "      <td>1.313410</td>\n",
       "      <td>-6.997032</td>\n",
       "      <td>2.995715</td>\n",
       "      <td>6.490741</td>\n",
       "      <td>-8.289175</td>\n",
       "      <td>-4.474739</td>\n",
       "      <td>-0.075545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183120</td>\n",
       "      <td>-0.285397</td>\n",
       "      <td>0.173588</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>-0.065112</td>\n",
       "      <td>-0.034913</td>\n",
       "      <td>0.014787</td>\n",
       "      <td>-0.086154</td>\n",
       "      <td>-0.044431</td>\n",
       "      <td>0.005240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>10.425983</td>\n",
       "      <td>1.535229</td>\n",
       "      <td>-4.551858</td>\n",
       "      <td>5.880482</td>\n",
       "      <td>0.200096</td>\n",
       "      <td>-1.730529</td>\n",
       "      <td>1.564345</td>\n",
       "      <td>-9.085990</td>\n",
       "      <td>4.725697</td>\n",
       "      <td>3.724238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064097</td>\n",
       "      <td>-0.167127</td>\n",
       "      <td>-0.033676</td>\n",
       "      <td>-0.102816</td>\n",
       "      <td>0.069599</td>\n",
       "      <td>0.147102</td>\n",
       "      <td>0.117062</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>-0.086795</td>\n",
       "      <td>0.056485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>3.283702</td>\n",
       "      <td>-3.405428</td>\n",
       "      <td>6.880994</td>\n",
       "      <td>-4.535354</td>\n",
       "      <td>3.572747</td>\n",
       "      <td>-0.137921</td>\n",
       "      <td>-4.267502</td>\n",
       "      <td>-4.196969</td>\n",
       "      <td>1.809773</td>\n",
       "      <td>1.672450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071849</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>-0.419401</td>\n",
       "      <td>0.041343</td>\n",
       "      <td>-0.190247</td>\n",
       "      <td>-0.300575</td>\n",
       "      <td>-0.306367</td>\n",
       "      <td>0.153455</td>\n",
       "      <td>-0.137392</td>\n",
       "      <td>0.093190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-1.385950</td>\n",
       "      <td>-2.689048</td>\n",
       "      <td>9.674512</td>\n",
       "      <td>-2.941767</td>\n",
       "      <td>-1.034115</td>\n",
       "      <td>0.403298</td>\n",
       "      <td>-0.048209</td>\n",
       "      <td>-4.701085</td>\n",
       "      <td>-2.244827</td>\n",
       "      <td>-4.828343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098919</td>\n",
       "      <td>0.394296</td>\n",
       "      <td>0.129172</td>\n",
       "      <td>0.172837</td>\n",
       "      <td>0.148669</td>\n",
       "      <td>0.103528</td>\n",
       "      <td>-0.388466</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>-0.147310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.541618</td>\n",
       "      <td>-5.999288</td>\n",
       "      <td>-4.645316</td>\n",
       "      <td>-5.452456</td>\n",
       "      <td>-3.989303</td>\n",
       "      <td>-0.751013</td>\n",
       "      <td>4.801612</td>\n",
       "      <td>7.150239</td>\n",
       "      <td>5.945537</td>\n",
       "      <td>-1.153986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232487</td>\n",
       "      <td>-0.034238</td>\n",
       "      <td>0.611768</td>\n",
       "      <td>-0.026796</td>\n",
       "      <td>0.053872</td>\n",
       "      <td>-0.113795</td>\n",
       "      <td>0.159599</td>\n",
       "      <td>0.142362</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.235167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-0.188198</td>\n",
       "      <td>3.654933</td>\n",
       "      <td>-5.119015</td>\n",
       "      <td>3.031778</td>\n",
       "      <td>3.558307</td>\n",
       "      <td>-2.231274</td>\n",
       "      <td>6.067173</td>\n",
       "      <td>-1.113531</td>\n",
       "      <td>4.883285</td>\n",
       "      <td>4.302158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142441</td>\n",
       "      <td>-0.184542</td>\n",
       "      <td>0.144752</td>\n",
       "      <td>-0.086936</td>\n",
       "      <td>-0.187736</td>\n",
       "      <td>-0.152929</td>\n",
       "      <td>0.078705</td>\n",
       "      <td>0.074424</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.286949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1       PC2       PC3       PC4        PC5       PC6       PC7  \\\n",
       "0    -5.607536 -1.682347 -7.015973  4.330058 -10.430326  1.448676 -0.339384   \n",
       "1    -3.538310 -3.150178 -7.407143  2.021023  -0.004542 -1.633807  1.738065   \n",
       "2   -15.839628  4.202032 -7.473620 -3.989203  -0.965320  4.723331  4.754412   \n",
       "3    -2.981441 -3.859699  7.544679 -9.073383   2.978680 -0.192978 -0.001371   \n",
       "4    -1.384403 -3.122986 -8.490395  1.313410  -6.997032  2.995715  6.490741   \n",
       "..         ...       ...       ...       ...        ...       ...       ...   \n",
       "410  10.425983  1.535229 -4.551858  5.880482   0.200096 -1.730529  1.564345   \n",
       "411   3.283702 -3.405428  6.880994 -4.535354   3.572747 -0.137921 -4.267502   \n",
       "412  -1.385950 -2.689048  9.674512 -2.941767  -1.034115  0.403298 -0.048209   \n",
       "413   0.541618 -5.999288 -4.645316 -5.452456  -3.989303 -0.751013  4.801612   \n",
       "414  -0.188198  3.654933 -5.119015  3.031778   3.558307 -2.231274  6.067173   \n",
       "\n",
       "          PC8       PC9      PC10  ...     PC347     PC348     PC349  \\\n",
       "0   -4.611228 -6.788621  0.124128  ...  0.122797 -0.035993  0.021245   \n",
       "1   -2.154232 -1.976465  3.327816  ... -0.239402  0.223499  0.037284   \n",
       "2    0.333156 -7.130679  3.160779  ...  0.138348 -0.121853  0.008060   \n",
       "3   -0.443693  1.448083 -1.900667  ... -0.010307  0.020917  0.316684   \n",
       "4   -8.289175 -4.474739 -0.075545  ... -0.183120 -0.285397  0.173588   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "410 -9.085990  4.725697  3.724238  ... -0.064097 -0.167127 -0.033676   \n",
       "411 -4.196969  1.809773  1.672450  ...  0.071849  0.085973 -0.419401   \n",
       "412 -4.701085 -2.244827 -4.828343  ...  0.098919  0.394296  0.129172   \n",
       "413  7.150239  5.945537 -1.153986  ...  0.232487 -0.034238  0.611768   \n",
       "414 -1.113531  4.883285  4.302158  ... -0.142441 -0.184542  0.144752   \n",
       "\n",
       "        PC350     PC351     PC352     PC353     PC354     PC355     PC356  \n",
       "0   -0.200851 -0.265693 -0.253483 -0.112400 -0.133370  0.304537 -0.063550  \n",
       "1    0.030717  0.095446  0.119005  0.024348  0.031293 -0.077573  0.071014  \n",
       "2    0.107734 -0.011509  0.166177 -0.009932 -0.237096 -0.168790  0.477852  \n",
       "3    0.064382  0.169967 -0.110248 -0.436463 -0.094482 -0.396167  0.132111  \n",
       "4    0.027797 -0.065112 -0.034913  0.014787 -0.086154 -0.044431  0.005240  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "410 -0.102816  0.069599  0.147102  0.117062  0.056653 -0.086795  0.056485  \n",
       "411  0.041343 -0.190247 -0.300575 -0.306367  0.153455 -0.137392  0.093190  \n",
       "412  0.172837  0.148669  0.103528 -0.388466  0.201509  0.014009 -0.147310  \n",
       "413 -0.026796  0.053872 -0.113795  0.159599  0.142362 -0.002071  0.235167  \n",
       "414 -0.086936 -0.187736 -0.152929  0.078705  0.074424  0.009693  0.286949  \n",
       "\n",
       "[415 rows x 356 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_x_test_pca = test_pca.iloc[:,:356]\n",
    "bert_x_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:55:41] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:43] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:45] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:47] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:49] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:51] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:53] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:55] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:57] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:58] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:00] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:02] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:04] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:06] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:09] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:11] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:13] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:15] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:17] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:18] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:20] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:22] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:23] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:56:25] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:27] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:29] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:31] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:33] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:35] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:36] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:38] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:40] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:42] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:44] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:46] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:48] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:50] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:52] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:54] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"scoring\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.1743492 ,  4.7892876 ,  6.800895  , ...,  0.28430042,\n",
       "         5.980476  ,  7.1330895 ],\n",
       "       [ 1.1190295 ,  3.0830994 ,  1.955303  , ..., -0.14808875,\n",
       "         2.0956457 ,  9.084604  ],\n",
       "       [-0.39958256,  0.50161624,  2.4947705 , ...,  0.51456773,\n",
       "         1.074606  , -1.3440343 ],\n",
       "       ...,\n",
       "       [-0.8980709 ,  0.06025499, -5.3436737 , ...,  1.0374243 ,\n",
       "        -5.4192557 , -8.594514  ],\n",
       "       [ 0.98975474,  1.1734122 ,  0.7384171 , ..., -0.912478  ,\n",
       "        -0.38347915,  2.086996  ],\n",
       "       [ 0.26858583,  0.5745545 ,  2.0688338 , ...,  1.1316127 ,\n",
       "         0.69402087,  4.5865593 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final PCA implementations file on the test dataset\n",
    "# Define the model\n",
    "bert_model = XGBRegressor(n_estimators=100,max_depth = 5,learning_rate = 0.1, subsample = 0.7, colsample_bytree = 0.8, scoring = 'neg_mean_squared_error') #16695.37712703339\n",
    "# Your code here\n",
    "\n",
    "multioutputregressor = MultiOutputRegressor(bert_model)\n",
    "# Fit the model\n",
    "multioutputregressor.fit(bert_x_pca,bert_y) # Your code here\n",
    "\n",
    "# Get predictions\n",
    "bert_predictions = multioutputregressor.predict(bert_x_test_pca)# Your code here\n",
    "\n",
    "\n",
    "bert_predictions\n",
    "# # Calculate MAE\n",
    "# error = mae(bert_predictions,bert_y_val,multioutput='raw_values') # Your code here\n",
    "\n",
    "# # Uncomment to print MAE\n",
    "# print(\"Mean Absolute Error for each collumn:\" , error)\n",
    "# print(f\"Mean of mae: {np.mean(error)}\")\n",
    "\n",
    "# # Check your answer\n",
    "# #step_2.check()\n",
    "# #LR: 1= 1116.448, 0.01 = 480.97, 0.1 = 333.445\n",
    "# #n_est: 10 = 487.954, 100 = 333.445, 1000 = 333.424\n",
    "# #max_depth: 10 = 340.772, 5 = 333.445, 1 = 356.496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = pd.DataFrame(bert_predictions)\n",
    "final_prediction.columns = bert_y.columns\n",
    "final_prediction.to_csv('final_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
