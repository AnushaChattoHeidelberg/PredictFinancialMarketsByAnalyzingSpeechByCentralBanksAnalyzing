{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5880fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Keerthan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\keerthan\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
<<<<<<< HEAD
    "import zipfile\n",
=======

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
    "import nltk\n",
    "import re\n",
    "import operator\n",
    "import csv\n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from gensim.models import KeyedVectors\n",
    "nltk.download('words')\n",
    "!pip install transformers\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 2,

   "id": "81a898e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile(\"../../Data/merged_finance_1w_2w.zip\")\n",
    "df = pd.read_csv(zf.open('merged_finance_1w_2w.csv'))"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 3,

   "id": "462bc4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DATE                                            ARTICLE  \\\n",
      "0      1997-01-07  [\"Bank of Japan's December review of monetary ...   \n",
      "1      1997-01-07  ['Mr. Matsushita considers the role of monetar...   \n",
      "2      1997-01-08  ['Ms. Rivlin discusses the prudential regulati...   \n",
      "3      1997-01-08  ['Mr. Meyer examines the role for structural m...   \n",
      "4      1997-01-08  ['Mr. Davies gives his personal view of EMU Sp...   \n",
      "...           ...                                                ...   \n",
      "34052  2021-03-03  ['Introductory comments at the press conferenc...   \n",
      "34053  2021-03-03  ['Randal K Quarles: Themistocles and the mathe...   \n",
      "34054  2021-03-03  ['Johannes Beermann: Annual accounts 2020\\n', ...   \n",
      "34055  2021-03-03  ['SPEECH\\n', '\\n', 'Unconventional fiscal and ...   \n",
      "34056  2021-03-03  ['SPEECH\\n', '\\n', 'Mind the gap(s): monetary ...   \n",
      "\n",
      "      Diff_VIX_1d Diff_VIX_1w Diff_VIX_2w      date1w      date2w   OPEN  \\\n",
      "0           19.35         NaN         NaN  1997-01-14  1997-01-21  20.46   \n",
      "1           19.35         NaN         NaN  1997-01-14  1997-01-21  20.46   \n",
      "2           20.24         NaN         NaN  1997-01-15  1997-01-22   18.6   \n",
      "3           20.24         NaN         NaN  1997-01-15  1997-01-22   18.6   \n",
      "4           20.24         NaN         NaN  1997-01-15  1997-01-22   18.6   \n",
      "...           ...         ...         ...         ...         ...    ...   \n",
      "34052       26.67         NaN         NaN  2021-03-10  2021-03-17  26.67   \n",
      "34053       26.67         NaN         NaN  2021-03-10  2021-03-17  26.67   \n",
      "34054       26.67         NaN         NaN  2021-03-10  2021-03-17  26.67   \n",
      "34055       26.67         NaN         NaN  2021-03-10  2021-03-17  26.67   \n",
      "34056       26.67         NaN         NaN  2021-03-10  2021-03-17  26.67   \n",
      "\n",
      "        HIGH    LOW  CLOSE  \n",
      "0      20.71  19.31  19.35  \n",
      "1      20.71  19.31  19.35  \n",
      "2      20.53   18.6  20.24  \n",
      "3      20.53   18.6  20.24  \n",
      "4      20.53   18.6  20.24  \n",
      "...      ...    ...    ...  \n",
      "34052  26.79  22.45   22.8  \n",
      "34053  26.79  22.45   22.8  \n",
      "34054  26.79  22.45   22.8  \n",
      "34055  26.79  22.45   22.8  \n",
      "34056  26.79  22.45   22.8  \n",
      "\n",
      "[34057 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2939c20",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTICLE</th>\n",
       "      <th>Diff_VIX_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Guy Quaden: The National Bank of Belgium - a...</td>\n",
       "      <td>11.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Guy Quaden: A changing IMF and World Bank\\n'...</td>\n",
       "      <td>22.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['1.\\n', '\\n', 'Central Banks and money: an ev...</td>\n",
       "      <td>28.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Guy Quaden: The Euro - a milestone on the pa...</td>\n",
       "      <td>20.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Guy Quaden: The Euro - a milestone on the pa...</td>\n",
       "      <td>20.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17023</th>\n",
       "      <td>['Zeti Akhtar Aziz: Grow your business – acces...</td>\n",
       "      <td>16.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17024</th>\n",
       "      <td>['Mohd Razif bin Abd Kadir: Islamic finance an...</td>\n",
       "      <td>23.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17025</th>\n",
       "      <td>['Encik Abdul Rasheed Ghaffour: Revolutionisin...</td>\n",
       "      <td>9.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17026</th>\n",
       "      <td>['Zeti Akhtar Aziz: Nurturing young talent in ...</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17027</th>\n",
       "      <td>['Datuk Zamani Abdul Ghani: Role of developmen...</td>\n",
       "      <td>12.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17028 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ARTICLE  Diff_VIX_1d\n",
       "0      ['Guy Quaden: The National Bank of Belgium - a...        11.69\n",
       "1      ['Guy Quaden: A changing IMF and World Bank\\n'...        22.10\n",
       "2      ['1.\\n', '\\n', 'Central Banks and money: an ev...        28.38\n",
       "3      ['Guy Quaden: The Euro - a milestone on the pa...        20.31\n",
       "4      ['Guy Quaden: The Euro - a milestone on the pa...        20.31\n",
       "...                                                  ...          ...\n",
       "17023  ['Zeti Akhtar Aziz: Grow your business – acces...        16.77\n",
       "17024  ['Mohd Razif bin Abd Kadir: Islamic finance an...        23.73\n",
       "17025  ['Encik Abdul Rasheed Ghaffour: Revolutionisin...         9.81\n",
       "17026  ['Zeti Akhtar Aziz: Nurturing young talent in ...        13.40\n",
       "17027  ['Datuk Zamani Abdul Ghani: Role of developmen...        12.96\n",
       "\n",
       "[17028 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "source": [
    "df = df.drop(columns = [\"DATE\", \"Diff_VIX_1w\", \"Diff_VIX_2w\", \"date1w\", \"date2w\", \"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01656a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Diff_VIX_1d\": \"VIX_1day\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0394bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ARTICLE\"].replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "id": "bfc4ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe88cd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTICLE</th>\n",
       "      <th>VIX_1day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Bank of Japan's December review of monetary ...</td>\n",
       "      <td>19.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Mr. Matsushita considers the role of monetar...</td>\n",
       "      <td>19.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Ms. Rivlin discusses the prudential regulati...</td>\n",
       "      <td>20.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Mr. Meyer examines the role for structural m...</td>\n",
       "      <td>20.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Mr. Davies gives his personal view of EMU Sp...</td>\n",
       "      <td>20.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34052</th>\n",
       "      <td>['Introductory comments at the press conferenc...</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34053</th>\n",
       "      <td>['Randal K Quarles: Themistocles and the mathe...</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34054</th>\n",
       "      <td>['Johannes Beermann: Annual accounts 2020', 'S...</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34055</th>\n",
       "      <td>['SPEECH', '', 'Unconventional fiscal and mone...</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34056</th>\n",
       "      <td>['SPEECH', '', 'Mind the gap(s): monetary poli...</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34047 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ARTICLE VIX_1day\n",
       "0      [\"Bank of Japan's December review of monetary ...    19.35\n",
       "1      ['Mr. Matsushita considers the role of monetar...    19.35\n",
       "2      ['Ms. Rivlin discusses the prudential regulati...    20.24\n",
       "3      ['Mr. Meyer examines the role for structural m...    20.24\n",
       "4      ['Mr. Davies gives his personal view of EMU Sp...    20.24\n",
       "...                                                  ...      ...\n",
       "34052  ['Introductory comments at the press conferenc...    26.67\n",
       "34053  ['Randal K Quarles: Themistocles and the mathe...    26.67\n",
       "34054  ['Johannes Beermann: Annual accounts 2020', 'S...    26.67\n",
       "34055  ['SPEECH', '', 'Unconventional fiscal and mone...    26.67\n",
       "34056  ['SPEECH', '', 'Mind the gap(s): monetary poli...    26.67\n",
       "\n",
       "[34047 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f572c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VIX_1day'].str.contains('Diff_VIX_1d').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31bcc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.VIX_1day != 'Diff_VIX_1d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daa1b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VIX_1day'].str.contains('Diff_VIX_1d').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
=======
   "execution_count": 22,
>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "96b0b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in 'â€–?!.,â€™\"#$%Ã©\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 10,
>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "56182143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████████████████████████████████████████████████████████████████████| 34046/34046 [00:14<00:00, 2406.01it/s]\n",
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\3743434513.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ARTICLE\"] = df[\"ARTICLE\"].progress_apply(lambda x: clean_text(x))\n"
=======

      "100%|██████████████████████████████████████████████████████████████████████████| 17028/17028 [00:06<00:00, 2623.77it/s]\n"
>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     ]
    }
   ],
   "source": [
    "df[\"ARTICLE\"] = df[\"ARTICLE\"].progress_apply(lambda x: clean_text(x))\n",
    "sentences = df[\"ARTICLE\"].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 11,
   "id": "6c7a6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regular expressions for numbers and links\n",
    "num_regex = r'\\d+' # matches one or more digits\n",
    "link_regex = r'https?://\\S+' # matches http or https followed by any non-space characters\n",
    "\n",
    "# remove numbers and links from the text column\n",
    "df['ARTICLE'] = df['ARTICLE'].apply(lambda x: re.sub(num_regex, '', x)) \n",
    "df['ARTICLE'] = df['ARTICLE'].apply(lambda x: re.sub(link_regex, '', x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "16c76710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "0        Bank of Japan s December review of monetary an...\n",
      "1         Mr Matsushita considers the role of monetary ...\n",
      "2         Ms Rivlin discusses the prudential regulation...\n",
      "3         Mr Meyer examines the role for structural mac...\n",
      "4         Mr Davies gives his personal view of EMU Spee...\n",
      "                               ...                        \n",
      "34052     Introductory comments at the press conference...\n",
      "34053     Randal K Quarles Themistocles and the mathema...\n",
      "34054     Johannes Beermann Annual accounts 2020   Spee...\n",
      "34055     SPEECH      Unconventional fiscal and monetar...\n",
      "34056     SPEECH      Mind the gaps monetary policy and...\n",
      "Name: ARTICLE, Length: 34046, dtype: object\n"
=======
      "URLs have been successfully removed\n",
      "0         Guy Quaden The National Bank of Belgium   a c...\n",
      "1         Guy Quaden A changing IMF and World Bank   Sp...\n",
      "2               Central Banks and money an everchanging...\n",
      "3         Guy Quaden The Euro   a milestone on the path...\n",
      "4         Guy Quaden The Euro   a milestone on the path...\n",
      "                               ...                        \n",
      "17023     Zeti Akhtar Aziz Grow your business  access t...\n",
      "17024     Mohd Razif bin Abd Kadir Islamic finance and ...\n",
      "17025     Encik Abdul Rasheed Ghaffour Revolutionising ...\n",
      "17026     Zeti Akhtar Aziz Nurturing young talent in Ma...\n",
      "17027     Datuk Zamani Abdul Ghani Role of development ...\n",
      "Name: ARTICLE, Length: 17028, dtype: object\n"
>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     ]
    }
   ],
   "source": [
    "if 'http' not in df['ARTICLE'].values and 'https' not in df['ARTICLE'].values:\n",
    "    print('URLs have been successfully removed')\n",
    "else:\n",
    "    print('URLs have not been removed')\n",
    "print(df[\"ARTICLE\"])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "id": "4c23c28b",
=======

   "execution_count": 10,
   "id": "12454f19",
>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    # remove all url links\n",
    "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6eb039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\3251165487.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ARTICLE\"] = [pre_process(i) for i in df[\"ARTICLE\"]]\n"
     ]
    }
   ],
   "source": [
    "df[\"ARTICLE\"] = [pre_process(i) for i in df[\"ARTICLE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a7c7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34046, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71492bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        bank of japan s december review of monetary an...\n",
      "1         mr matsushita considers the role of monetary ...\n",
      "2         ms rivlin discusses the prudential regulation...\n",
      "3         mr meyer examines the role for structural mac...\n",
      "4         mr davies gives his personal view of emu spee...\n",
      "                               ...                        \n",
      "34052     introductory comments at the press conference...\n",
      "34053     randal k quarles themistocles and the mathema...\n",
      "34054     johannes beermann annual accounts speech by d...\n",
      "34055     speech unconventional fiscal and monetary pol...\n",
      "34056     speech mind the gaps monetary policy and the ...\n",
      "Name: ARTICLE, Length: 34046, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"ARTICLE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d7ec8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\2358396148.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ARTICLE'] = df['ARTICLE'].apply(clean_sent)\n"
     ]
    }
   ],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def clean_sent(sent):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
    "     if w.lower() in words or not w.isalpha())\n",
    "\n",
    "df['ARTICLE'] = df['ARTICLE'].apply(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 14,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "be5eb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======

   "execution_count": 15,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "71b583c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████████████████████████████████████████████████████████████████████| 34046/34046 [00:30<00:00, 1134.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [00:38<00:00, 886.01it/s]\n"
=======

      "100%|██████████████████████████████████████████████████████████████████████████| 17028/17028 [00:08<00:00, 1959.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 17028/17028 [00:10<00:00, 1573.29it/s]\n"

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'bank': 375572, 'of': 3602100, 'japan': 35836, 's': 111360, 'review': 109668}\n"
=======

      "{'guy': 278, 'the': 3440085, 'national': 36097, 'bank': 187831, 'of': 1801753}\n"

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     ]
    }
   ],
   "source": [
    "sentences = df[\"ARTICLE\"].progress_apply(lambda x: x.split()).values\n",
    "vocab = build_vocab(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======

   "execution_count": 16,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "9e6ddc30",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "from gensim.models import KeyedVectors\n",
    "\n",

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
    "news_path = '../../Embeddings/GoogleNews-vectors-negative300.bin'\n",

    "embeddings_index = KeyedVectors.load_word2vec_format(news_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======

   "execution_count": 17,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "af1cae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "    \n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======

   "execution_count": 18,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "eb587fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████████████████████████████████████████████████████████████████████| 25769/25769 [00:02<00:00, 9144.05it/s]"
=======

      "100%|██████████████████████████████████████████████████████████████████████████| 25773/25773 [00:04<00:00, 6034.35it/s]"

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Found embeddings for 94.27% of vocab\n",
      "Found embeddings for  86.32% of all text\n"

     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======

   "execution_count": 19,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "c2f9d0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[('of', 3602100),\n",
       " ('to', 2882948),\n",
       " ('and', 2810740),\n",
       " ('a', 1656082),\n",
       " ('labour', 41070),\n",
       " ('behaviour', 11902),\n",
       " ('covid', 5992),\n",
       " ('analyses', 4658),\n",
       " ('analyse', 2128),\n",
       " ('doesnt', 2016)]"
      ]
     },
     "execution_count": 25,
=======

       "[('of', 1801753),\n",
       " ('to', 1442017),\n",
       " ('and', 1405911),\n",
       " ('a', 828324),\n",
       " ('labour', 20570),\n",
       " ('behaviour', 5956),\n",
       " ('covid', 2996),\n",
       " ('analyses', 2329),\n",
       " ('analyse', 1064),\n",
       " ('doesnt', 1008)]"
      ]
     },
     "execution_count": 19,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 out of vocabulary words with their frequency\n",
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======

   "execution_count": 20,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "1b5e6c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [05:18<00:00, 106.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [01:10<00:00, 482.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [00:44<00:00, 773.76it/s]\n"
=======

      "100%|███████████████████████████████████████████████████████████████████████████| 17028/17028 [00:25<00:00, 671.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 17028/17028 [00:08<00:00, 1996.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 17028/17028 [00:08<00:00, 1988.04it/s]\n"

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     ]
    }
   ],
   "source": [
    "sentences = df[\"ARTICLE\"].progress_apply(lambda x: x.split())\n",
    "to_remove = ['a','to','of','and']\n",
    "sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======

   "execution_count": 21,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "fb46b870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████████████████████████████████████████████████████████████████████| 25765/25765 [00:09<00:00, 2609.23it/s]"
=======

      "100%|█████████████████████████████████████████████████████████████████████████| 25769/25769 [00:00<00:00, 35977.32it/s]"

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Found embeddings for 94.29% of vocab\n",
      "Found embeddings for  99.86% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"

     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======

   "execution_count": 22,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
   "id": "be55b26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[('labour', 41070),\n",
       " ('behaviour', 11902),\n",
       " ('covid', 5992),\n",
       " ('analyses', 4658),\n",
       " ('analyse', 2128),\n",
       " ('doesnt', 2016),\n",
       " ('defence', 1918),\n",
       " ('learnt', 1836),\n",
       " ('cheque', 1244),\n",
       " ('didnt', 1196),\n",
       " ('macao', 1110),\n",
       " ('mimeo', 884),\n",
       " ('channelled', 696),\n",
       " ('shouldnt', 694),\n",
       " ('wasnt', 582),\n",
       " ('channelling', 512),\n",
       " ('sabine', 502),\n",
       " ('resolvability', 464),\n",
       " ('elb', 464),\n",
       " ('kiley', 448)]"
=======

       "[('labour', 20570),\n",
       " ('behaviour', 5956),\n",
       " ('covid', 2996),\n",
       " ('analyses', 2329),\n",
       " ('analyse', 1064),\n",
       " ('doesnt', 1008),\n",
       " ('defence', 959),\n",
       " ('learnt', 918),\n",
       " ('cheque', 622),\n",
       " ('didnt', 599),\n",
       " ('macao', 555),\n",
       " ('mimeo', 442),\n",
       " ('channelled', 348),\n",
       " ('shouldnt', 347),\n",
       " ('wasnt', 291),\n",
       " ('channelling', 256),\n",
       " ('sabine', 251),\n",
       " ('elb', 232),\n",
       " ('resolvability', 232),\n",
       " ('kiley', 224)]"
>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9d87913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispell_dict = {'colour':'color',\n",
    "                'centre':'center',\n",
    "                'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'harbour': 'harbor',\n",
    "                'flavour': 'flavor',\n",
    "                'wasnt': 'was not',\n",
    "                'labour': 'labor',\n",
    "                'learnt':'learn',\n",
    "                'defence': 'defense',\n",
    "                'analyses': 'analysis',\n",
    "                'behaviour': 'behavior',\n",
    "                'travelled': 'traveled',\n",
    "                'channelled': 'channeled',\n",
    "                'channelling': 'channeling',\n",
    "                'labour': 'labor',\n",
    "                'analyse': 'analize',\n",
    "                'shouldnt':'should not',\n",
    "                'favourite':'favorite',\n",
    "                'travelling':'traveling',\n",
    "                'counselling':'counseling',\n",
    "                'theatre':'theater',\n",
    "                'cancelled':'canceled',\n",
    "                'labour':'labor',\n",
    "                'organisation':'organization',\n",
    "                'wwii':'world war 2',\n",
    "                'citicise':'criticize',\n",
    "                'instagram': 'social medium',\n",
    "                'whatsapp': 'social medium',\n",
    "                'snapchat': 'social medium'\n",
    "               }\n",
    "\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e577b292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [00:58<00:00, 580.08it/s]\n",
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\4107646593.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ARTICLE\"] = df[\"ARTICLE\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [02:14<00:00, 253.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [02:15<00:00, 250.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bank': 375572, 'of': 3602100, 'japan': 35836, 's': 111360, 'review': 109668}\n"
     ]
    }
   ],
   "source": [
    "df[\"ARTICLE\"] = df[\"ARTICLE\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "sentences = df[\"ARTICLE\"].progress_apply(lambda x: x.split()).values\n",
    "vocab = build_vocab(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0f8afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 25753/25753 [00:06<00:00, 4027.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 94.33% of vocab\n",
      "Found embeddings for  86.41% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91368a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 3602100),\n",
       " ('to', 2882948),\n",
       " ('and', 2810740),\n",
       " ('a', 1656082),\n",
       " ('covid', 5992),\n",
       " ('cheque', 1244),\n",
       " ('macao', 1110),\n",
       " ('mimeo', 884),\n",
       " ('sabine', 502),\n",
       " ('resolvability', 464),\n",
       " ('elb', 464),\n",
       " ('kiley', 448),\n",
       " ('grey', 346),\n",
       " ('exter', 286),\n",
       " ('aluminium', 262),\n",
       " ('rix', 250),\n",
       " ('berne', 248),\n",
       " ('saron', 246),\n",
       " ('paolo', 232),\n",
       " ('pank', 216)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2650cc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [00:56<00:00, 606.32it/s]\n",
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\2170417985.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ARTICLE\"] = df[\"ARTICLE\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [01:38<00:00, 344.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [01:08<00:00, 495.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 34046/34046 [00:54<00:00, 625.26it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"ARTICLE\"] = df[\"ARTICLE\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "sentences = df[\"ARTICLE\"].progress_apply(lambda x: x.split())\n",
    "to_remove = ['a','to','of','and']\n",
    "sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7aa4a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 25749/25749 [00:05<00:00, 4826.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 94.35% of vocab\n",
      "Found embeddings for  99.96% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca0ff9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('covid', 5992),\n",
       " ('cheque', 1244),\n",
       " ('macao', 1110),\n",
       " ('mimeo', 884),\n",
       " ('sabine', 502),\n",
       " ('resolvability', 464),\n",
       " ('elb', 464),\n",
       " ('kiley', 448),\n",
       " ('grey', 346),\n",
       " ('exter', 286),\n",
       " ('aluminium', 262),\n",
       " ('rix', 250),\n",
       " ('berne', 248),\n",
       " ('saron', 246),\n",
       " ('paolo', 232),\n",
       " ('pank', 216),\n",
       " ('enquiry', 198),\n",
       " ('whiteside', 196),\n",
       " ('faust', 186),\n",
       " ('schnabel', 172)]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 35,
=======
     "execution_count": 29,

>>>>>>> 7e8598a35ecbad13b23403de3740551b440bda10
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 out of vocabulary words with their frequency\n",
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0641d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-uncased'\n",
    "\n",
    "config = BertConfig.from_pretrained(pretrained_weights, num_labels=2)\n",
    "model = BertForSequenceClassification.from_pretrained(pretrained_weights, config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1885a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 768\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57b2f459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\374627972.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for text in tqdm_notebook(texts)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8591827990d84addbc6f59ddbf94acd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34046 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\374627972.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"test_X\"] = encode_text(df[\"ARTICLE\"])\n",
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\374627972.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for text in tqdm_notebook(texts)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa1ee222491437a866c8b22e9989058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34046 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode_text(texts):\n",
    "    \n",
    "    # encoding\n",
    "    X = [tokenizer.encode(text, add_special_tokens=True, max_length=MAX_LENGTH) \n",
    "         for text in tqdm_notebook(texts)]\n",
    "           \n",
    "    # padding\n",
    "    X = [x + [0 for _ in range(MAX_LENGTH-len(x))] for x in X]            \n",
    "    \n",
    "    return X\n",
    "\n",
    "df[\"test_X\"] = encode_text(df[\"ARTICLE\"])\n",
    "test_X = encode_text(df[\"ARTICLE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94f21074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTICLE</th>\n",
       "      <th>VIX_1day</th>\n",
       "      <th>test_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank of japan s review of monetary and economi...</td>\n",
       "      <td>19.35</td>\n",
       "      <td>[101, 2924, 1997, 2900, 1055, 3319, 1997, 1219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the role of monetary policy in japan of a spee...</td>\n",
       "      <td>19.35</td>\n",
       "      <td>[101, 1996, 2535, 1997, 12194, 3343, 1999, 290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the prudential regulation of and how to improv...</td>\n",
       "      <td>20.24</td>\n",
       "      <td>[101, 1996, 10975, 12672, 19909, 7816, 1997, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the role for structural in the monetary policy...</td>\n",
       "      <td>20.24</td>\n",
       "      <td>[101, 1996, 2535, 2005, 8332, 1999, 1996, 1219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>his personal view of emu speech by the deputy ...</td>\n",
       "      <td>20.24</td>\n",
       "      <td>[101, 2010, 3167, 3193, 1997, 7861, 2226, 4613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34052</th>\n",
       "      <td>introductory at the press conference to presen...</td>\n",
       "      <td>26.67</td>\n",
       "      <td>[101, 23889, 2012, 1996, 2811, 3034, 2000, 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34053</th>\n",
       "      <td>k and the the role of stress testing speech by...</td>\n",
       "      <td>26.67</td>\n",
       "      <td>[101, 1047, 1998, 1996, 1996, 2535, 1997, 6911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34054</th>\n",
       "      <td>johannes annual speech by johannes member of t...</td>\n",
       "      <td>26.67</td>\n",
       "      <td>[101, 12470, 3296, 4613, 2011, 12470, 2266, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34055</th>\n",
       "      <td>speech unconventional fiscal and monetary poli...</td>\n",
       "      <td>26.67</td>\n",
       "      <td>[101, 4613, 23693, 10807, 1998, 12194, 3343, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34056</th>\n",
       "      <td>speech mind the monetary policy and the way ou...</td>\n",
       "      <td>26.67</td>\n",
       "      <td>[101, 4613, 2568, 1996, 12194, 3343, 1998, 199...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34046 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ARTICLE VIX_1day  \\\n",
       "0      bank of japan s review of monetary and economi...    19.35   \n",
       "1      the role of monetary policy in japan of a spee...    19.35   \n",
       "2      the prudential regulation of and how to improv...    20.24   \n",
       "3      the role for structural in the monetary policy...    20.24   \n",
       "4      his personal view of emu speech by the deputy ...    20.24   \n",
       "...                                                  ...      ...   \n",
       "34052  introductory at the press conference to presen...    26.67   \n",
       "34053  k and the the role of stress testing speech by...    26.67   \n",
       "34054  johannes annual speech by johannes member of t...    26.67   \n",
       "34055  speech unconventional fiscal and monetary poli...    26.67   \n",
       "34056  speech mind the monetary policy and the way ou...    26.67   \n",
       "\n",
       "                                                  test_X  \n",
       "0      [101, 2924, 1997, 2900, 1055, 3319, 1997, 1219...  \n",
       "1      [101, 1996, 2535, 1997, 12194, 3343, 1999, 290...  \n",
       "2      [101, 1996, 10975, 12672, 19909, 7816, 1997, 1...  \n",
       "3      [101, 1996, 2535, 2005, 8332, 1999, 1996, 1219...  \n",
       "4      [101, 2010, 3167, 3193, 1997, 7861, 2226, 4613...  \n",
       "...                                                  ...  \n",
       "34052  [101, 23889, 2012, 1996, 2811, 3034, 2000, 255...  \n",
       "34053  [101, 1047, 1998, 1996, 1996, 2535, 1997, 6911...  \n",
       "34054  [101, 12470, 3296, 4613, 2011, 12470, 2266, 19...  \n",
       "34055  [101, 4613, 23693, 10807, 1998, 12194, 3343, 2...  \n",
       "34056  [101, 4613, 2568, 1996, 12194, 3343, 1998, 199...  \n",
       "\n",
       "[34046 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7aae3df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34046, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b176970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[\"VIX_1day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2db7995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keerthan\\AppData\\Local\\Temp\\ipykernel_12396\\2477332197.py:2: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df2 = df2[..., np.newaxis] # i.e. x[..., None]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df2 = df2[..., np.newaxis] # i.e. x[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49211638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34046, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a71f4a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['19.35'],\n",
       "       ['19.35'],\n",
       "       ['20.24'],\n",
       "       ...,\n",
       "       ['26.67'],\n",
       "       ['26.67'],\n",
       "       ['26.67']], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6847f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmessage = 'Diff_VIX_1d'\n",
    "for i in df2:\n",
    "    if newmessage in i:\n",
    "        print('found')\n",
    "        print(np.where(df2 == i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf820926",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('g2g.csv', 'a+', newline ='')\n",
    " \n",
    "# writing the data into the file\n",
    "with file:   \n",
    "    write = csv.writer(file)\n",
    "    write.writerows(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16348c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_x = pd.read_csv('g2g.csv', header = None)\n",
    "bert_y = df2\n",
    "bert_x_test  = pd.read_csv('../data/x_test_pf4T2aK.csv')\n",
    "random_submission = pd.read_csv('../data/random_submission_example.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34ec6f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68093, 768)\n",
      "(34046, 1)\n"
     ]
    }
   ],
   "source": [
    "print(bert_x.shape)\n",
    "print(bert_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1be26ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2924</td>\n",
       "      <td>1997</td>\n",
       "      <td>2900</td>\n",
       "      <td>1055</td>\n",
       "      <td>3319</td>\n",
       "      <td>1997</td>\n",
       "      <td>12194</td>\n",
       "      <td>1998</td>\n",
       "      <td>3171</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>3961</td>\n",
       "      <td>2844</td>\n",
       "      <td>2023</td>\n",
       "      <td>2458</td>\n",
       "      <td>2001</td>\n",
       "      <td>2011</td>\n",
       "      <td>1996</td>\n",
       "      <td>2139</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>1996</td>\n",
       "      <td>2535</td>\n",
       "      <td>1997</td>\n",
       "      <td>12194</td>\n",
       "      <td>3343</td>\n",
       "      <td>1999</td>\n",
       "      <td>2900</td>\n",
       "      <td>1997</td>\n",
       "      <td>1037</td>\n",
       "      <td>...</td>\n",
       "      <td>4487</td>\n",
       "      <td>13102</td>\n",
       "      <td>2884</td>\n",
       "      <td>2058</td>\n",
       "      <td>1996</td>\n",
       "      <td>2925</td>\n",
       "      <td>2004</td>\n",
       "      <td>1996</td>\n",
       "      <td>4130</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>1996</td>\n",
       "      <td>10975</td>\n",
       "      <td>12672</td>\n",
       "      <td>19909</td>\n",
       "      <td>7816</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>2129</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>2005</td>\n",
       "      <td>2068</td>\n",
       "      <td>2000</td>\n",
       "      <td>2693</td>\n",
       "      <td>2037</td>\n",
       "      <td>2219</td>\n",
       "      <td>10738</td>\n",
       "      <td>1999</td>\n",
       "      <td>2023</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>1996</td>\n",
       "      <td>2535</td>\n",
       "      <td>2005</td>\n",
       "      <td>8332</td>\n",
       "      <td>1999</td>\n",
       "      <td>1996</td>\n",
       "      <td>12194</td>\n",
       "      <td>3343</td>\n",
       "      <td>2832</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>12194</td>\n",
       "      <td>3343</td>\n",
       "      <td>1996</td>\n",
       "      <td>11581</td>\n",
       "      <td>2063</td>\n",
       "      <td>2005</td>\n",
       "      <td>2023</td>\n",
       "      <td>7709</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>2010</td>\n",
       "      <td>3167</td>\n",
       "      <td>3193</td>\n",
       "      <td>1997</td>\n",
       "      <td>7861</td>\n",
       "      <td>2226</td>\n",
       "      <td>4613</td>\n",
       "      <td>2011</td>\n",
       "      <td>1996</td>\n",
       "      <td>...</td>\n",
       "      <td>9879</td>\n",
       "      <td>12882</td>\n",
       "      <td>1999</td>\n",
       "      <td>1997</td>\n",
       "      <td>3020</td>\n",
       "      <td>3037</td>\n",
       "      <td>2004</td>\n",
       "      <td>2057</td>\n",
       "      <td>1999</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68088</th>\n",
       "      <td>101</td>\n",
       "      <td>23889</td>\n",
       "      <td>2012</td>\n",
       "      <td>1996</td>\n",
       "      <td>2811</td>\n",
       "      <td>3034</td>\n",
       "      <td>2000</td>\n",
       "      <td>2556</td>\n",
       "      <td>1996</td>\n",
       "      <td>3296</td>\n",
       "      <td>...</td>\n",
       "      <td>2966</td>\n",
       "      <td>5576</td>\n",
       "      <td>2000</td>\n",
       "      <td>10663</td>\n",
       "      <td>2023</td>\n",
       "      <td>2270</td>\n",
       "      <td>2740</td>\n",
       "      <td>5325</td>\n",
       "      <td>4621</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68089</th>\n",
       "      <td>101</td>\n",
       "      <td>1047</td>\n",
       "      <td>1998</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>2535</td>\n",
       "      <td>1997</td>\n",
       "      <td>6911</td>\n",
       "      <td>5604</td>\n",
       "      <td>4613</td>\n",
       "      <td>...</td>\n",
       "      <td>1996</td>\n",
       "      <td>1997</td>\n",
       "      <td>1037</td>\n",
       "      <td>2846</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>3361</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68090</th>\n",
       "      <td>101</td>\n",
       "      <td>12470</td>\n",
       "      <td>3296</td>\n",
       "      <td>4613</td>\n",
       "      <td>2011</td>\n",
       "      <td>12470</td>\n",
       "      <td>2266</td>\n",
       "      <td>1997</td>\n",
       "      <td>1996</td>\n",
       "      <td>3237</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68091</th>\n",
       "      <td>101</td>\n",
       "      <td>4613</td>\n",
       "      <td>23693</td>\n",
       "      <td>10807</td>\n",
       "      <td>1998</td>\n",
       "      <td>12194</td>\n",
       "      <td>3343</td>\n",
       "      <td>2012</td>\n",
       "      <td>1996</td>\n",
       "      <td>5717</td>\n",
       "      <td>...</td>\n",
       "      <td>2004</td>\n",
       "      <td>1037</td>\n",
       "      <td>2765</td>\n",
       "      <td>2045</td>\n",
       "      <td>2003</td>\n",
       "      <td>2625</td>\n",
       "      <td>9531</td>\n",
       "      <td>2005</td>\n",
       "      <td>11412</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68092</th>\n",
       "      <td>101</td>\n",
       "      <td>4613</td>\n",
       "      <td>2568</td>\n",
       "      <td>1996</td>\n",
       "      <td>12194</td>\n",
       "      <td>3343</td>\n",
       "      <td>1998</td>\n",
       "      <td>1996</td>\n",
       "      <td>2126</td>\n",
       "      <td>2041</td>\n",
       "      <td>...</td>\n",
       "      <td>4610</td>\n",
       "      <td>2064</td>\n",
       "      <td>2633</td>\n",
       "      <td>2128</td>\n",
       "      <td>26915</td>\n",
       "      <td>2036</td>\n",
       "      <td>3464</td>\n",
       "      <td>10599</td>\n",
       "      <td>2096</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68093 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5     6      7     8     9    ...  \\\n",
       "0      101   2924   1997   2900   1055   3319  1997  12194  1998  3171  ...   \n",
       "1      101   1996   2535   1997  12194   3343  1999   2900  1997  1037  ...   \n",
       "2      101   1996  10975  12672  19909   7816  1997   1998  2129  2000  ...   \n",
       "3      101   1996   2535   2005   8332   1999  1996  12194  3343  2832  ...   \n",
       "4      101   2010   3167   3193   1997   7861  2226   4613  2011  1996  ...   \n",
       "...    ...    ...    ...    ...    ...    ...   ...    ...   ...   ...  ...   \n",
       "68088  101  23889   2012   1996   2811   3034  2000   2556  1996  3296  ...   \n",
       "68089  101   1047   1998   1996   1996   2535  1997   6911  5604  4613  ...   \n",
       "68090  101  12470   3296   4613   2011  12470  2266   1997  1996  3237  ...   \n",
       "68091  101   4613  23693  10807   1998  12194  3343   2012  1996  5717  ...   \n",
       "68092  101   4613   2568   1996  12194   3343  1998   1996  2126  2041  ...   \n",
       "\n",
       "        758    759   760    761    762   763    764    765    766  767  \n",
       "0      2007   3961  2844   2023   2458  2001   2011   1996   2139  102  \n",
       "1      4487  13102  2884   2058   1996  2925   2004   1996   4130  102  \n",
       "2      2005   2068  2000   2693   2037  2219  10738   1999   2023  102  \n",
       "3      1999  12194  3343   1996  11581  2063   2005   2023   7709  102  \n",
       "4      9879  12882  1999   1997   3020  3037   2004   2057   1999  102  \n",
       "...     ...    ...   ...    ...    ...   ...    ...    ...    ...  ...  \n",
       "68088  2966   5576  2000  10663   2023  2270   2740   5325   4621  102  \n",
       "68089  1996   1997  1037   2846   1997  1998   3361   2008   2008  102  \n",
       "68090     0      0     0      0      0     0      0      0      0    0  \n",
       "68091  2004   1037  2765   2045   2003  2625   9531   2005  11412  102  \n",
       "68092  4610   2064  2633   2128  26915  2036   3464  10599   2096  102  \n",
       "\n",
       "[68093 rows x 768 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c212288",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [68093, 34046]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12396\\3978377656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbert_x_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbert_x_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbert_y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbert_y_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbert_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2415\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2417\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [68093, 34046]"
     ]
    }
   ],
   "source": [
    "bert_x_train,bert_x_val,bert_y_train,bert_y_val = train_test_split(bert_x,bert_y,train_size = 0.8,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed10b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bert_x_train.shape)\n",
    "print(bert_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad639e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "if a['Names'].str.contains('Mel').any():\n",
    "    print (\"Mel is there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = XGBRegressor(n_estimators=100,max_depth = 5,learning_rate = 0.1, subsample = 0.7, colsample_bytree = 0.8, scoring = 'neg_mean_squared_error') #16695.37712703339\n",
    "# Your code here\n",
    "\n",
    "multioutputregressor = MultiOutputRegressor(bert_model)\n",
    "# Fit the model\n",
    "multioutputregressor.fit(bert_x_train,bert_y_train) # Your code here\n",
    "\n",
    "# Get predictions\n",
    "bert_predictions = multioutputregressor.predict(bert_x_val)# Your code here\n",
    "\n",
    "# Calculate MAE\n",
    "error = mae(bert_predictions,bert_y_val,multioutput='raw_values') # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error for each collumn:\" , error)\n",
    "print(f\"Mean of mae: {np.mean(error)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16571ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c753ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mse\n",
    "error = mse(bert_predictions,bert_y_val,squared = False) # Your code here\n",
    "\n",
    "# Uncomment to print MSE\n",
    "print(\"Mean Squared Error:\" , error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47828e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "bert_model = XGBRegressor(n_estimators=100,max_depth = 5,learning_rate = 0.1, subsample = 0.7, colsample_bytree = 0.8, scoring = 'neg_mean_squared_error') #16695.37712703339\n",
    "# Your code here\n",
    "train_x = bert_x.values\n",
    "test_x = bert_x_test.values\n",
    "multioutputregressor = MultiOutputRegressor(bert_model)\n",
    "# Fit the model\n",
    "multioutputregressor.fit(train_x,bert_y) # Your code here\n",
    "\n",
    "# Get predictions\n",
    "bert_predictions = multioutputregressor.predict(test_x)# Your code here\n",
    "\n",
    "final_df = pd.DataFrame(bert_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2ab95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
